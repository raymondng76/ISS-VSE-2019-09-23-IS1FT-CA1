{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from CA1_Yolo import *\n",
    "from keras.optimizers import Adam\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"../data/image/\"\n",
    "anno_dir = \"../data/annotation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anno, labels = read_annotation_files(img_dir, anno_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 distances: 5179.013307955627\n",
      "iter: 2 distances: 604.3330094426443\n",
      "iter: 3 distances: 326.2661983757942\n",
      "iter: 4 distances: 192.78979431726424\n",
      "iter: 5 distances: 116.29829712576718\n",
      "iter: 6 distances: 88.05611838862728\n",
      "iter: 7 distances: 68.19114180508996\n",
      "iter: 8 distances: 47.26887080773634\n",
      "iter: 9 distances: 38.28024096838901\n",
      "iter: 10 distances: 21.788784095032607\n",
      "iter: 11 distances: 16.866838875484834\n",
      "iter: 12 distances: 7.757274250962514\n",
      "iter: 13 distances: 11.176253683007443\n",
      "iter: 14 distances: 14.325222349562765\n",
      "iter: 15 distances: 15.004251976055716\n",
      "iter: 16 distances: 22.88884396449402\n",
      "iter: 17 distances: 13.35578595470531\n",
      "iter: 18 distances: 12.759565707564308\n",
      "iter: 19 distances: 8.482574332176622\n",
      "iter: 20 distances: 7.686161752734023\n",
      "iter: 21 distances: 5.682759387782925\n",
      "iter: 22 distances: 4.13569558252419\n",
      "iter: 23 distances: 1.7880149433834007\n",
      "iter: 24 distances: 1.554028316213501\n",
      "iter: 25 distances: 1.671409580148171\n",
      "iter: 26 distances: 1.5849365407984544\n"
     ]
    }
   ],
   "source": [
    "anchor_boxes = generateAnchorBoxes(all_anno, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 9, 26, 21, 34, 40, 43, 66, 43, 29, 62, 113, 67, 42, 84, 65, 103, 96]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "train_valid_split = int(0.8 * len(all_anno))\n",
    "np.random.shuffle(all_anno)\n",
    "train_anno = all_anno[:train_valid_split]\n",
    "valid_anno = all_anno[train_valid_split:]\n",
    "max_boxes = max([len(anno['object']) for anno in (train_anno + valid_anno)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(\n",
    "    annotations=train_anno,\n",
    "    max_boxes=max_boxes,\n",
    "    anchors=anchor_boxes,\n",
    "    labels=labels,\n",
    "    batch_size=2,\n",
    "    width=416,\n",
    "    height=416,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = DataGenerator(\n",
    "    annotations=valid_anno,\n",
    "    max_boxes=max_boxes,\n",
    "    anchors=anchor_boxes,\n",
    "    labels=labels,\n",
    "    batch_size=2,\n",
    "    width=416,\n",
    "    height=416,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Workspace\\GitHub\\ISS-VSE-2019-09-23-IS1FT-CA1\\code\\CA1_Yolo.py:397: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model, infer_mode = YoloV3(\n",
    "    numcls=len(labels),\n",
    "    anchors=anchor_boxes,\n",
    "    max_grid=[416, 416],\n",
    "    batch_size=2,\n",
    "    threshold=0.5,\n",
    "    max_boxes=max_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
      "                                                                 leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
      "                                                                 leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
      "                                                                 leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n",
      "                                                                 leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
      "                                                                 leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
      "                                                                 leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
      "                                                                 leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
      "                                                                 leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
      "                                                                 leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n",
      "                                                                 leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
      "                                                                 leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
      "                                                                 leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n",
      "                                                                 leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 5 524288      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 5 2048        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 4096        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 5 2048        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 4096        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 5 2048        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 2 131328      leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 5 2048        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 2 1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 5 2048        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 2 1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 2 1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 2 32768       leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 4096        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 5 2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 2 1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 2 21525       leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 2 10773       leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 2 5397        leaky_re_lu_71[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 61,318,815\n",
      "Trainable params: 61,266,719\n",
      "Non-trainable params: 52,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "infer_mode.build((416,416))\n",
    "infer_mode.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=1e-4, clipnorm=0.001)\n",
    "train_model.compile(loss=dummy_loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = create_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "306/306 [==============================] - 174s 568ms/step - loss: 52.0943 - yolo_loss_layer_1_loss: 7.3452 - yolo_loss_layer_2_loss: 13.2315 - yolo_loss_layer_3_loss: 29.1895 - val_loss: 46.0383 - val_yolo_loss_layer_1_loss: 33.5750 - val_yolo_loss_layer_2_loss: 4.6725 - val_yolo_loss_layer_3_loss: 5.4620\n",
      "Epoch 2/300\n",
      "306/306 [==============================] - 165s 540ms/step - loss: 7.3960 - yolo_loss_layer_1_loss: 3.6690 - yolo_loss_layer_2_loss: 0.3189 - yolo_loss_layer_3_loss: 1.0804 - val_loss: 8.0138 - val_yolo_loss_layer_1_loss: 5.1456 - val_yolo_loss_layer_2_loss: 0.1271 - val_yolo_loss_layer_3_loss: 0.4156\n",
      "Epoch 3/300\n",
      "306/306 [==============================] - 170s 557ms/step - loss: 6.0379 - yolo_loss_layer_1_loss: 3.3541 - yolo_loss_layer_2_loss: 0.1640 - yolo_loss_layer_3_loss: 0.1973 - val_loss: 7.1612 - val_yolo_loss_layer_1_loss: 4.6495 - val_yolo_loss_layer_2_loss: 0.0905 - val_yolo_loss_layer_3_loss: 0.1023\n",
      "Epoch 4/300\n",
      "306/306 [==============================] - 177s 578ms/step - loss: 5.7925 - yolo_loss_layer_1_loss: 3.2832 - yolo_loss_layer_2_loss: 0.1051 - yolo_loss_layer_3_loss: 0.0896 - val_loss: 6.8712 - val_yolo_loss_layer_1_loss: 4.4349 - val_yolo_loss_layer_2_loss: 0.0676 - val_yolo_loss_layer_3_loss: 0.0584\n",
      "Epoch 5/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 5.8222 - yolo_loss_layer_1_loss: 3.3432 - yolo_loss_layer_2_loss: 0.1226 - yolo_loss_layer_3_loss: 0.0511 - val_loss: 6.1908 - val_yolo_loss_layer_1_loss: 3.7739 - val_yolo_loss_layer_2_loss: 0.0797 - val_yolo_loss_layer_3_loss: 0.0362\n",
      "Epoch 6/300\n",
      "306/306 [==============================] - 181s 593ms/step - loss: 5.6151 - yolo_loss_layer_1_loss: 3.1823 - yolo_loss_layer_2_loss: 0.1017 - yolo_loss_layer_3_loss: 0.0340 - val_loss: 5.5866 - val_yolo_loss_layer_1_loss: 3.1932 - val_yolo_loss_layer_2_loss: 0.0693 - val_yolo_loss_layer_3_loss: 0.0312\n",
      "Epoch 7/300\n",
      "306/306 [==============================] - 175s 571ms/step - loss: 5.5278 - yolo_loss_layer_1_loss: 3.1320 - yolo_loss_layer_2_loss: 0.0842 - yolo_loss_layer_3_loss: 0.0239 - val_loss: 5.4090 - val_yolo_loss_layer_1_loss: 3.0361 - val_yolo_loss_layer_2_loss: 0.0713 - val_yolo_loss_layer_3_loss: 0.0189\n",
      "Epoch 8/300\n",
      "306/306 [==============================] - 177s 579ms/step - loss: 5.4282 - yolo_loss_layer_1_loss: 3.0569 - yolo_loss_layer_2_loss: 0.0756 - yolo_loss_layer_3_loss: 0.0178 - val_loss: 5.5707 - val_yolo_loss_layer_1_loss: 3.2458 - val_yolo_loss_layer_2_loss: 0.0388 - val_yolo_loss_layer_3_loss: 0.0136\n",
      "Epoch 9/300\n",
      "306/306 [==============================] - 175s 571ms/step - loss: 5.2767 - yolo_loss_layer_1_loss: 2.9348 - yolo_loss_layer_2_loss: 0.0617 - yolo_loss_layer_3_loss: 0.0125 - val_loss: 5.1526 - val_yolo_loss_layer_1_loss: 2.8379 - val_yolo_loss_layer_2_loss: 0.0403 - val_yolo_loss_layer_3_loss: 0.0117\n",
      "Epoch 10/300\n",
      "306/306 [==============================] - 164s 536ms/step - loss: 5.0624 - yolo_loss_layer_1_loss: 2.7263 - yolo_loss_layer_2_loss: 0.0693 - yolo_loss_layer_3_loss: 0.0095 - val_loss: 4.9639 - val_yolo_loss_layer_1_loss: 2.6660 - val_yolo_loss_layer_2_loss: 0.0382 - val_yolo_loss_layer_3_loss: 0.0078\n",
      "Epoch 11/300\n",
      "306/306 [==============================] - 168s 548ms/step - loss: 5.0075 - yolo_loss_layer_1_loss: 2.6851 - yolo_loss_layer_2_loss: 0.0674 - yolo_loss_layer_3_loss: 0.0079 - val_loss: 5.0660 - val_yolo_loss_layer_1_loss: 2.7786 - val_yolo_loss_layer_2_loss: 0.0389 - val_yolo_loss_layer_3_loss: 0.0064\n",
      "Epoch 12/300\n",
      "306/306 [==============================] - 154s 502ms/step - loss: 4.9729 - yolo_loss_layer_1_loss: 2.6614 - yolo_loss_layer_2_loss: 0.0688 - yolo_loss_layer_3_loss: 0.0057 - val_loss: 5.2112 - val_yolo_loss_layer_1_loss: 2.9359 - val_yolo_loss_layer_2_loss: 0.0381 - val_yolo_loss_layer_3_loss: 0.0052\n",
      "Epoch 13/300\n",
      "306/306 [==============================] - 181s 591ms/step - loss: 4.9231 - yolo_loss_layer_1_loss: 2.6149 - yolo_loss_layer_2_loss: 0.0758 - yolo_loss_layer_3_loss: 0.0056 - val_loss: 5.1276 - val_yolo_loss_layer_1_loss: 2.8623 - val_yolo_loss_layer_2_loss: 0.0387 - val_yolo_loss_layer_3_loss: 0.0049\n",
      "Epoch 14/300\n",
      "306/306 [==============================] - 184s 602ms/step - loss: 4.8573 - yolo_loss_layer_1_loss: 2.5735 - yolo_loss_layer_2_loss: 0.0629 - yolo_loss_layer_3_loss: 0.0045 - val_loss: 4.9688 - val_yolo_loss_layer_1_loss: 2.7133 - val_yolo_loss_layer_2_loss: 0.0401 - val_yolo_loss_layer_3_loss: 0.0046\n",
      "Epoch 15/300\n",
      "306/306 [==============================] - 176s 574ms/step - loss: 4.8535 - yolo_loss_layer_1_loss: 2.5751 - yolo_loss_layer_2_loss: 0.0693 - yolo_loss_layer_3_loss: 0.0036 - val_loss: 4.9863 - val_yolo_loss_layer_1_loss: 2.7447 - val_yolo_loss_layer_2_loss: 0.0380 - val_yolo_loss_layer_3_loss: 0.0034\n",
      "Epoch 16/300\n",
      "306/306 [==============================] - 168s 549ms/step - loss: 4.7319 - yolo_loss_layer_1_loss: 2.4758 - yolo_loss_layer_2_loss: 0.0584 - yolo_loss_layer_3_loss: 0.0029 - val_loss: 4.9224 - val_yolo_loss_layer_1_loss: 2.6972 - val_yolo_loss_layer_2_loss: 0.0328 - val_yolo_loss_layer_3_loss: 0.0031\n",
      "Epoch 17/300\n",
      "306/306 [==============================] - 163s 533ms/step - loss: 4.6683 - yolo_loss_layer_1_loss: 2.4231 - yolo_loss_layer_2_loss: 0.0590 - yolo_loss_layer_3_loss: 0.0025 - val_loss: 4.8538 - val_yolo_loss_layer_1_loss: 2.6351 - val_yolo_loss_layer_2_loss: 0.0381 - val_yolo_loss_layer_3_loss: 0.0022\n",
      "Epoch 18/300\n",
      "306/306 [==============================] - 168s 547ms/step - loss: 4.6027 - yolo_loss_layer_1_loss: 2.3697 - yolo_loss_layer_2_loss: 0.0579 - yolo_loss_layer_3_loss: 0.0021 - val_loss: 5.1901 - val_yolo_loss_layer_1_loss: 2.9864 - val_yolo_loss_layer_2_loss: 0.0342 - val_yolo_loss_layer_3_loss: 0.0019\n",
      "Epoch 19/300\n",
      "306/306 [==============================] - 171s 559ms/step - loss: 4.6564 - yolo_loss_layer_1_loss: 2.4293 - yolo_loss_layer_2_loss: 0.0630 - yolo_loss_layer_3_loss: 0.0019 - val_loss: 7.2183 - val_yolo_loss_layer_1_loss: 5.0211 - val_yolo_loss_layer_2_loss: 0.0388 - val_yolo_loss_layer_3_loss: 0.0017\n",
      "Epoch 20/300\n",
      "306/306 [==============================] - 163s 534ms/step - loss: 4.5758 - yolo_loss_layer_1_loss: 2.3596 - yolo_loss_layer_2_loss: 0.0631 - yolo_loss_layer_3_loss: 0.0016 - val_loss: 4.8627 - val_yolo_loss_layer_1_loss: 2.6795 - val_yolo_loss_layer_2_loss: 0.0357 - val_yolo_loss_layer_3_loss: 0.0013\n",
      "Epoch 21/300\n",
      "306/306 [==============================] - 186s 609ms/step - loss: 4.5062 - yolo_loss_layer_1_loss: 2.3006 - yolo_loss_layer_2_loss: 0.0634 - yolo_loss_layer_3_loss: 0.0015 - val_loss: 4.8286 - val_yolo_loss_layer_1_loss: 2.6547 - val_yolo_loss_layer_2_loss: 0.0375 - val_yolo_loss_layer_3_loss: 0.0013\n",
      "Epoch 22/300\n",
      "306/306 [==============================] - 175s 572ms/step - loss: 4.5072 - yolo_loss_layer_1_loss: 2.3157 - yolo_loss_layer_2_loss: 0.0605 - yolo_loss_layer_3_loss: 0.0013 - val_loss: 4.5896 - val_yolo_loss_layer_1_loss: 2.4274 - val_yolo_loss_layer_2_loss: 0.0364 - val_yolo_loss_layer_3_loss: 0.0010\n",
      "Epoch 23/300\n",
      "306/306 [==============================] - 156s 511ms/step - loss: 4.4143 - yolo_loss_layer_1_loss: 2.2419 - yolo_loss_layer_2_loss: 0.0518 - yolo_loss_layer_3_loss: 9.9217e-04 - val_loss: 4.5783 - val_yolo_loss_layer_1_loss: 2.4206 - val_yolo_loss_layer_2_loss: 0.0427 - val_yolo_loss_layer_3_loss: 9.4327e-04\n",
      "Epoch 24/300\n",
      "306/306 [==============================] - 176s 576ms/step - loss: 4.3418 - yolo_loss_layer_1_loss: 2.1735 - yolo_loss_layer_2_loss: 0.0583 - yolo_loss_layer_3_loss: 9.7015e-04 - val_loss: 4.9266 - val_yolo_loss_layer_1_loss: 2.7829 - val_yolo_loss_layer_2_loss: 0.0391 - val_yolo_loss_layer_3_loss: 7.8721e-04\n",
      "Epoch 25/300\n",
      "306/306 [==============================] - 171s 558ms/step - loss: 4.2763 - yolo_loss_layer_1_loss: 2.1138 - yolo_loss_layer_2_loss: 0.0630 - yolo_loss_layer_3_loss: 8.3529e-04 - val_loss: 4.5329 - val_yolo_loss_layer_1_loss: 2.4026 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 7.9248e-04\n",
      "Epoch 26/300\n",
      "306/306 [==============================] - 170s 556ms/step - loss: 4.2272 - yolo_loss_layer_1_loss: 2.0936 - yolo_loss_layer_2_loss: 0.0446 - yolo_loss_layer_3_loss: 7.4602e-04 - val_loss: 4.7520 - val_yolo_loss_layer_1_loss: 2.6346 - val_yolo_loss_layer_2_loss: 0.0331 - val_yolo_loss_layer_3_loss: 6.8266e-04\n",
      "Epoch 27/300\n",
      "306/306 [==============================] - 184s 601ms/step - loss: 4.1771 - yolo_loss_layer_1_loss: 2.0461 - yolo_loss_layer_2_loss: 0.0515 - yolo_loss_layer_3_loss: 7.1973e-04 - val_loss: 4.5091 - val_yolo_loss_layer_1_loss: 2.3953 - val_yolo_loss_layer_2_loss: 0.0391 - val_yolo_loss_layer_3_loss: 5.7769e-04\n",
      "Epoch 28/300\n",
      "306/306 [==============================] - 165s 540ms/step - loss: 4.1337 - yolo_loss_layer_1_loss: 2.0131 - yolo_loss_layer_2_loss: 0.0508 - yolo_loss_layer_3_loss: 6.1523e-04 - val_loss: 4.8257 - val_yolo_loss_layer_1_loss: 2.7226 - val_yolo_loss_layer_2_loss: 0.0385 - val_yolo_loss_layer_3_loss: 5.0096e-04\n",
      "Epoch 29/300\n",
      "306/306 [==============================] - 161s 528ms/step - loss: 4.1773 - yolo_loss_layer_1_loss: 2.0566 - yolo_loss_layer_2_loss: 0.0606 - yolo_loss_layer_3_loss: 5.4437e-04 - val_loss: 4.6264 - val_yolo_loss_layer_1_loss: 2.5343 - val_yolo_loss_layer_2_loss: 0.0368 - val_yolo_loss_layer_3_loss: 5.1652e-04\n",
      "Epoch 30/300\n",
      "306/306 [==============================] - 184s 602ms/step - loss: 4.0358 - yolo_loss_layer_1_loss: 1.9375 - yolo_loss_layer_2_loss: 0.0478 - yolo_loss_layer_3_loss: 5.3459e-04 - val_loss: 4.4355 - val_yolo_loss_layer_1_loss: 2.3551 - val_yolo_loss_layer_2_loss: 0.0347 - val_yolo_loss_layer_3_loss: 5.2899e-04\n",
      "Epoch 31/300\n",
      "306/306 [==============================] - 171s 559ms/step - loss: 4.1086 - yolo_loss_layer_1_loss: 2.0193 - yolo_loss_layer_2_loss: 0.0483 - yolo_loss_layer_3_loss: 4.8540e-04 - val_loss: 4.5178 - val_yolo_loss_layer_1_loss: 2.4467 - val_yolo_loss_layer_2_loss: 0.0349 - val_yolo_loss_layer_3_loss: 3.8803e-04\n",
      "Epoch 32/300\n",
      "306/306 [==============================] - 161s 526ms/step - loss: 4.0385 - yolo_loss_layer_1_loss: 1.9528 - yolo_loss_layer_2_loss: 0.0543 - yolo_loss_layer_3_loss: 4.2121e-04 - val_loss: 4.8206 - val_yolo_loss_layer_1_loss: 2.7582 - val_yolo_loss_layer_2_loss: 0.0357 - val_yolo_loss_layer_3_loss: 4.0062e-04\n",
      "Epoch 33/300\n",
      "306/306 [==============================] - 175s 573ms/step - loss: 4.0188 - yolo_loss_layer_1_loss: 1.9439 - yolo_loss_layer_2_loss: 0.0530 - yolo_loss_layer_3_loss: 4.1459e-04 - val_loss: 4.6386 - val_yolo_loss_layer_1_loss: 2.5855 - val_yolo_loss_layer_2_loss: 0.0356 - val_yolo_loss_layer_3_loss: 3.7719e-04\n",
      "Epoch 34/300\n",
      "306/306 [==============================] - 162s 531ms/step - loss: 3.9204 - yolo_loss_layer_1_loss: 1.8580 - yolo_loss_layer_2_loss: 0.0492 - yolo_loss_layer_3_loss: 3.6659e-04 - val_loss: 4.3984 - val_yolo_loss_layer_1_loss: 2.3570 - val_yolo_loss_layer_2_loss: 0.0326 - val_yolo_loss_layer_3_loss: 3.2682e-04\n",
      "Epoch 35/300\n",
      "306/306 [==============================] - 168s 548ms/step - loss: 3.9356 - yolo_loss_layer_1_loss: 1.8793 - yolo_loss_layer_2_loss: 0.0517 - yolo_loss_layer_3_loss: 3.5373e-04 - val_loss: 4.4822 - val_yolo_loss_layer_1_loss: 2.4469 - val_yolo_loss_layer_2_loss: 0.0353 - val_yolo_loss_layer_3_loss: 3.5543e-04\n",
      "Epoch 36/300\n",
      "306/306 [==============================] - 169s 551ms/step - loss: 3.9327 - yolo_loss_layer_1_loss: 1.8861 - yolo_loss_layer_2_loss: 0.0514 - yolo_loss_layer_3_loss: 3.3849e-04 - val_loss: 4.6112 - val_yolo_loss_layer_1_loss: 2.5874 - val_yolo_loss_layer_2_loss: 0.0332 - val_yolo_loss_layer_3_loss: 2.8155e-04\n",
      "Epoch 37/300\n",
      "306/306 [==============================] - 173s 566ms/step - loss: 3.9171 - yolo_loss_layer_1_loss: 1.8835 - yolo_loss_layer_2_loss: 0.0473 - yolo_loss_layer_3_loss: 3.2929e-04 - val_loss: 4.5135 - val_yolo_loss_layer_1_loss: 2.4969 - val_yolo_loss_layer_2_loss: 0.0349 - val_yolo_loss_layer_3_loss: 2.7864e-04\n",
      "Epoch 38/300\n",
      "306/306 [==============================] - 175s 571ms/step - loss: 3.8001 - yolo_loss_layer_1_loss: 1.7643 - yolo_loss_layer_2_loss: 0.0586 - yolo_loss_layer_3_loss: 3.1111e-04 - val_loss: 4.3316 - val_yolo_loss_layer_1_loss: 2.3227 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 2.8103e-04\n",
      "Epoch 39/300\n",
      "306/306 [==============================] - 183s 599ms/step - loss: 3.8328 - yolo_loss_layer_1_loss: 1.8044 - yolo_loss_layer_2_loss: 0.0602 - yolo_loss_layer_3_loss: 3.0517e-04 - val_loss: 4.3395 - val_yolo_loss_layer_1_loss: 2.3389 - val_yolo_loss_layer_2_loss: 0.0365 - val_yolo_loss_layer_3_loss: 2.4876e-04\n",
      "Epoch 40/300\n",
      "306/306 [==============================] - 167s 546ms/step - loss: 3.7442 - yolo_loss_layer_1_loss: 1.7338 - yolo_loss_layer_2_loss: 0.0508 - yolo_loss_layer_3_loss: 2.7545e-04 - val_loss: 4.5827 - val_yolo_loss_layer_1_loss: 2.5897 - val_yolo_loss_layer_2_loss: 0.0380 - val_yolo_loss_layer_3_loss: 2.3145e-04\n",
      "Epoch 41/300\n",
      "306/306 [==============================] - 170s 556ms/step - loss: 3.7123 - yolo_loss_layer_1_loss: 1.7127 - yolo_loss_layer_2_loss: 0.0488 - yolo_loss_layer_3_loss: 2.5838e-04 - val_loss: 4.3539 - val_yolo_loss_layer_1_loss: 2.3734 - val_yolo_loss_layer_2_loss: 0.0339 - val_yolo_loss_layer_3_loss: 2.4554e-04\n",
      "Epoch 42/300\n",
      "306/306 [==============================] - 181s 590ms/step - loss: 3.6341 - yolo_loss_layer_1_loss: 1.6467 - yolo_loss_layer_2_loss: 0.0448 - yolo_loss_layer_3_loss: 2.5504e-04 - val_loss: 4.2192 - val_yolo_loss_layer_1_loss: 2.2446 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 2.4442e-04\n",
      "Epoch 43/300\n",
      "306/306 [==============================] - 161s 527ms/step - loss: 3.6404 - yolo_loss_layer_1_loss: 1.6519 - yolo_loss_layer_2_loss: 0.0542 - yolo_loss_layer_3_loss: 2.3093e-04 - val_loss: 4.3080 - val_yolo_loss_layer_1_loss: 2.3457 - val_yolo_loss_layer_2_loss: 0.0323 - val_yolo_loss_layer_3_loss: 2.3611e-04\n",
      "Epoch 44/300\n",
      "306/306 [==============================] - 161s 525ms/step - loss: 3.7051 - yolo_loss_layer_1_loss: 1.7348 - yolo_loss_layer_2_loss: 0.0447 - yolo_loss_layer_3_loss: 2.2448e-04 - val_loss: 4.0909 - val_yolo_loss_layer_1_loss: 2.1370 - val_yolo_loss_layer_2_loss: 0.0324 - val_yolo_loss_layer_3_loss: 1.9062e-04\n",
      "Epoch 45/300\n",
      "306/306 [==============================] - 172s 563ms/step - loss: 3.5944 - yolo_loss_layer_1_loss: 1.6237 - yolo_loss_layer_2_loss: 0.0532 - yolo_loss_layer_3_loss: 2.2518e-04 - val_loss: 4.2930 - val_yolo_loss_layer_1_loss: 2.3434 - val_yolo_loss_layer_2_loss: 0.0365 - val_yolo_loss_layer_3_loss: 2.1541e-04\n",
      "Epoch 46/300\n",
      "306/306 [==============================] - 166s 542ms/step - loss: 3.5421 - yolo_loss_layer_1_loss: 1.5834 - yolo_loss_layer_2_loss: 0.0496 - yolo_loss_layer_3_loss: 2.1774e-04 - val_loss: 4.0846 - val_yolo_loss_layer_1_loss: 2.1465 - val_yolo_loss_layer_2_loss: 0.0330 - val_yolo_loss_layer_3_loss: 1.8972e-04\n",
      "Epoch 47/300\n",
      "306/306 [==============================] - 172s 561ms/step - loss: 3.5389 - yolo_loss_layer_1_loss: 1.5937 - yolo_loss_layer_2_loss: 0.0440 - yolo_loss_layer_3_loss: 2.1458e-04 - val_loss: 4.4811 - val_yolo_loss_layer_1_loss: 2.5495 - val_yolo_loss_layer_2_loss: 0.0344 - val_yolo_loss_layer_3_loss: 2.2130e-04\n",
      "Epoch 48/300\n",
      "306/306 [==============================] - 168s 548ms/step - loss: 3.5292 - yolo_loss_layer_1_loss: 1.5790 - yolo_loss_layer_2_loss: 0.0567 - yolo_loss_layer_3_loss: 2.0489e-04 - val_loss: 4.2466 - val_yolo_loss_layer_1_loss: 2.3161 - val_yolo_loss_layer_2_loss: 0.0409 - val_yolo_loss_layer_3_loss: 1.9687e-04\n",
      "Epoch 49/300\n",
      "306/306 [==============================] - 170s 555ms/step - loss: 3.4702 - yolo_loss_layer_1_loss: 1.5377 - yolo_loss_layer_2_loss: 0.0465 - yolo_loss_layer_3_loss: 2.0868e-04 - val_loss: 4.0752 - val_yolo_loss_layer_1_loss: 2.1583 - val_yolo_loss_layer_2_loss: 0.0348 - val_yolo_loss_layer_3_loss: 1.8570e-04\n",
      "Epoch 50/300\n",
      "306/306 [==============================] - 189s 618ms/step - loss: 3.5182 - yolo_loss_layer_1_loss: 1.5902 - yolo_loss_layer_2_loss: 0.0495 - yolo_loss_layer_3_loss: 2.2560e-04 - val_loss: 4.1486 - val_yolo_loss_layer_1_loss: 2.2406 - val_yolo_loss_layer_2_loss: 0.0331 - val_yolo_loss_layer_3_loss: 1.7599e-04\n",
      "Epoch 51/300\n",
      "306/306 [==============================] - 178s 581ms/step - loss: 3.4133 - yolo_loss_layer_1_loss: 1.4957 - yolo_loss_layer_2_loss: 0.0464 - yolo_loss_layer_3_loss: 2.0314e-04 - val_loss: 4.2337 - val_yolo_loss_layer_1_loss: 2.3289 - val_yolo_loss_layer_2_loss: 0.0372 - val_yolo_loss_layer_3_loss: 1.7459e-04\n",
      "Epoch 52/300\n",
      "306/306 [==============================] - 164s 536ms/step - loss: 3.3735 - yolo_loss_layer_1_loss: 1.4586 - yolo_loss_layer_2_loss: 0.0511 - yolo_loss_layer_3_loss: 1.8501e-04 - val_loss: 4.3214 - val_yolo_loss_layer_1_loss: 2.4179 - val_yolo_loss_layer_2_loss: 0.0434 - val_yolo_loss_layer_3_loss: 2.0134e-04\n",
      "Epoch 53/300\n",
      "306/306 [==============================] - 176s 575ms/step - loss: 3.3433 - yolo_loss_layer_1_loss: 1.4322 - yolo_loss_layer_2_loss: 0.0547 - yolo_loss_layer_3_loss: 1.9617e-04 - val_loss: 4.4288 - val_yolo_loss_layer_1_loss: 2.5428 - val_yolo_loss_layer_2_loss: 0.0333 - val_yolo_loss_layer_3_loss: 1.9182e-04\n",
      "Epoch 54/300\n",
      "306/306 [==============================] - 169s 554ms/step - loss: 3.4121 - yolo_loss_layer_1_loss: 1.5107 - yolo_loss_layer_2_loss: 0.0522 - yolo_loss_layer_3_loss: 1.9182e-04 - val_loss: 4.0898 - val_yolo_loss_layer_1_loss: 2.2102 - val_yolo_loss_layer_2_loss: 0.0341 - val_yolo_loss_layer_3_loss: 1.7801e-04\n",
      "Epoch 55/300\n",
      "306/306 [==============================] - 167s 547ms/step - loss: 3.2812 - yolo_loss_layer_1_loss: 1.3930 - yolo_loss_layer_2_loss: 0.0466 - yolo_loss_layer_3_loss: 1.7901e-04 - val_loss: 4.1322 - val_yolo_loss_layer_1_loss: 2.2616 - val_yolo_loss_layer_2_loss: 0.0325 - val_yolo_loss_layer_3_loss: 1.7837e-04\n",
      "Epoch 56/300\n",
      "306/306 [==============================] - 162s 529ms/step - loss: 3.3039 - yolo_loss_layer_1_loss: 1.4199 - yolo_loss_layer_2_loss: 0.0493 - yolo_loss_layer_3_loss: 1.7184e-04 - val_loss: 4.5709 - val_yolo_loss_layer_1_loss: 2.7081 - val_yolo_loss_layer_2_loss: 0.0316 - val_yolo_loss_layer_3_loss: 1.8835e-04\n",
      "Epoch 57/300\n",
      "306/306 [==============================] - 168s 549ms/step - loss: 3.1963 - yolo_loss_layer_1_loss: 1.3227 - yolo_loss_layer_2_loss: 0.0460 - yolo_loss_layer_3_loss: 1.7926e-04 - val_loss: 4.0210 - val_yolo_loss_layer_1_loss: 2.1645 - val_yolo_loss_layer_2_loss: 0.0327 - val_yolo_loss_layer_3_loss: 1.7872e-04\n",
      "Epoch 58/300\n",
      "306/306 [==============================] - 183s 597ms/step - loss: 3.3167 - yolo_loss_layer_1_loss: 1.4517 - yolo_loss_layer_2_loss: 0.0447 - yolo_loss_layer_3_loss: 1.8624e-04 - val_loss: 4.3155 - val_yolo_loss_layer_1_loss: 2.4647 - val_yolo_loss_layer_2_loss: 0.0337 - val_yolo_loss_layer_3_loss: 1.7822e-04\n",
      "Epoch 59/300\n",
      "306/306 [==============================] - 164s 537ms/step - loss: 3.2305 - yolo_loss_layer_1_loss: 1.3688 - yolo_loss_layer_2_loss: 0.0481 - yolo_loss_layer_3_loss: 1.7552e-04 - val_loss: 4.0788 - val_yolo_loss_layer_1_loss: 2.2334 - val_yolo_loss_layer_2_loss: 0.0354 - val_yolo_loss_layer_3_loss: 1.7095e-04\n",
      "Epoch 60/300\n",
      "306/306 [==============================] - 178s 581ms/step - loss: 3.2296 - yolo_loss_layer_1_loss: 1.3645 - yolo_loss_layer_2_loss: 0.0584 - yolo_loss_layer_3_loss: 1.8227e-04 - val_loss: 4.3894 - val_yolo_loss_layer_1_loss: 2.5488 - val_yolo_loss_layer_2_loss: 0.0373 - val_yolo_loss_layer_3_loss: 1.6281e-04\n",
      "Epoch 61/300\n",
      "306/306 [==============================] - 170s 556ms/step - loss: 3.1486 - yolo_loss_layer_1_loss: 1.2972 - yolo_loss_layer_2_loss: 0.0514 - yolo_loss_layer_3_loss: 1.7395e-04 - val_loss: 4.1022 - val_yolo_loss_layer_1_loss: 2.2700 - val_yolo_loss_layer_2_loss: 0.0356 - val_yolo_loss_layer_3_loss: 1.5452e-04\n",
      "Epoch 62/300\n",
      "306/306 [==============================] - 179s 586ms/step - loss: 3.0644 - yolo_loss_layer_1_loss: 1.2267 - yolo_loss_layer_2_loss: 0.0445 - yolo_loss_layer_3_loss: 1.7746e-04 - val_loss: 4.2586 - val_yolo_loss_layer_1_loss: 2.4323 - val_yolo_loss_layer_2_loss: 0.0364 - val_yolo_loss_layer_3_loss: 1.7606e-04\n",
      "Epoch 63/300\n",
      "306/306 [==============================] - 178s 580ms/step - loss: 3.0732 - yolo_loss_layer_1_loss: 1.2361 - yolo_loss_layer_2_loss: 0.0507 - yolo_loss_layer_3_loss: 1.7329e-04 - val_loss: 4.1795 - val_yolo_loss_layer_1_loss: 2.3584 - val_yolo_loss_layer_2_loss: 0.0383 - val_yolo_loss_layer_3_loss: 1.5980e-04\n",
      "Epoch 64/300\n",
      "306/306 [==============================] - 172s 563ms/step - loss: 3.0182 - yolo_loss_layer_1_loss: 1.1970 - yolo_loss_layer_2_loss: 0.0419 - yolo_loss_layer_3_loss: 1.6642e-04 - val_loss: 4.0539 - val_yolo_loss_layer_1_loss: 2.2458 - val_yolo_loss_layer_2_loss: 0.0326 - val_yolo_loss_layer_3_loss: 1.6423e-04\n",
      "Epoch 65/300\n",
      "306/306 [==============================] - 167s 547ms/step - loss: 3.0410 - yolo_loss_layer_1_loss: 1.2272 - yolo_loss_layer_2_loss: 0.0416 - yolo_loss_layer_3_loss: 1.6328e-04 - val_loss: 4.1145 - val_yolo_loss_layer_1_loss: 2.3154 - val_yolo_loss_layer_2_loss: 0.0305 - val_yolo_loss_layer_3_loss: 1.5609e-04\n",
      "Epoch 66/300\n",
      "306/306 [==============================] - 175s 573ms/step - loss: 2.9686 - yolo_loss_layer_1_loss: 1.1561 - yolo_loss_layer_2_loss: 0.0473 - yolo_loss_layer_3_loss: 1.6612e-04 - val_loss: 4.1984 - val_yolo_loss_layer_1_loss: 2.3971 - val_yolo_loss_layer_2_loss: 0.0396 - val_yolo_loss_layer_3_loss: 1.5544e-04\n",
      "Epoch 67/300\n",
      "306/306 [==============================] - 153s 501ms/step - loss: 3.0282 - yolo_loss_layer_1_loss: 1.2246 - yolo_loss_layer_2_loss: 0.0453 - yolo_loss_layer_3_loss: 1.5367e-04 - val_loss: 4.1847 - val_yolo_loss_layer_1_loss: 2.3909 - val_yolo_loss_layer_2_loss: 0.0390 - val_yolo_loss_layer_3_loss: 1.3865e-04\n",
      "Epoch 68/300\n",
      "306/306 [==============================] - 168s 550ms/step - loss: 3.0337 - yolo_loss_layer_1_loss: 1.2371 - yolo_loss_layer_2_loss: 0.0451 - yolo_loss_layer_3_loss: 1.5991e-04 - val_loss: 4.2225 - val_yolo_loss_layer_1_loss: 2.4428 - val_yolo_loss_layer_2_loss: 0.0318 - val_yolo_loss_layer_3_loss: 1.6278e-04\n",
      "Epoch 69/300\n",
      "306/306 [==============================] - 176s 574ms/step - loss: 2.9677 - yolo_loss_layer_1_loss: 1.1822 - yolo_loss_layer_2_loss: 0.0412 - yolo_loss_layer_3_loss: 1.6136e-04 - val_loss: 4.1325 - val_yolo_loss_layer_1_loss: 2.3578 - val_yolo_loss_layer_2_loss: 0.0339 - val_yolo_loss_layer_3_loss: 1.4412e-04\n",
      "Epoch 70/300\n",
      "306/306 [==============================] - 158s 516ms/step - loss: 3.0569 - yolo_loss_layer_1_loss: 1.2756 - yolo_loss_layer_2_loss: 0.0438 - yolo_loss_layer_3_loss: 1.4884e-04 - val_loss: 3.9981 - val_yolo_loss_layer_1_loss: 2.2320 - val_yolo_loss_layer_2_loss: 0.0319 - val_yolo_loss_layer_3_loss: 1.3625e-04\n",
      "Epoch 71/300\n",
      "306/306 [==============================] - 184s 601ms/step - loss: 2.9076 - yolo_loss_layer_1_loss: 1.1330 - yolo_loss_layer_2_loss: 0.0437 - yolo_loss_layer_3_loss: 1.6255e-04 - val_loss: 4.1645 - val_yolo_loss_layer_1_loss: 2.4053 - val_yolo_loss_layer_2_loss: 0.0317 - val_yolo_loss_layer_3_loss: 1.4043e-04\n",
      "Epoch 72/300\n",
      "306/306 [==============================] - 163s 531ms/step - loss: 2.9480 - yolo_loss_layer_1_loss: 1.1794 - yolo_loss_layer_2_loss: 0.0444 - yolo_loss_layer_3_loss: 1.4451e-04 - val_loss: 4.2246 - val_yolo_loss_layer_1_loss: 2.4682 - val_yolo_loss_layer_2_loss: 0.0356 - val_yolo_loss_layer_3_loss: 1.5243e-04\n",
      "Epoch 73/300\n",
      "306/306 [==============================] - 168s 550ms/step - loss: 2.9350 - yolo_loss_layer_1_loss: 1.1802 - yolo_loss_layer_2_loss: 0.0373 - yolo_loss_layer_3_loss: 1.5080e-04 - val_loss: 4.0339 - val_yolo_loss_layer_1_loss: 2.2843 - val_yolo_loss_layer_2_loss: 0.0355 - val_yolo_loss_layer_3_loss: 1.6289e-04\n",
      "Epoch 74/300\n",
      "306/306 [==============================] - 167s 547ms/step - loss: 2.8469 - yolo_loss_layer_1_loss: 1.0897 - yolo_loss_layer_2_loss: 0.0463 - yolo_loss_layer_3_loss: 1.4960e-04 - val_loss: 4.1453 - val_yolo_loss_layer_1_loss: 2.4010 - val_yolo_loss_layer_2_loss: 0.0369 - val_yolo_loss_layer_3_loss: 1.3495e-04\n",
      "Epoch 75/300\n",
      "306/306 [==============================] - 181s 590ms/step - loss: 2.8274 - yolo_loss_layer_1_loss: 1.0772 - yolo_loss_layer_2_loss: 0.0457 - yolo_loss_layer_3_loss: 1.5460e-04 - val_loss: 3.9648 - val_yolo_loss_layer_1_loss: 2.2298 - val_yolo_loss_layer_2_loss: 0.0336 - val_yolo_loss_layer_3_loss: 1.3444e-04\n",
      "Epoch 76/300\n",
      "306/306 [==============================] - 164s 534ms/step - loss: 2.8265 - yolo_loss_layer_1_loss: 1.0853 - yolo_loss_layer_2_loss: 0.0432 - yolo_loss_layer_3_loss: 1.4279e-04 - val_loss: 4.1788 - val_yolo_loss_layer_1_loss: 2.4480 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 1.3350e-04\n",
      "Epoch 77/300\n",
      "306/306 [==============================] - 187s 610ms/step - loss: 2.8184 - yolo_loss_layer_1_loss: 1.0799 - yolo_loss_layer_2_loss: 0.0471 - yolo_loss_layer_3_loss: 1.5404e-04 - val_loss: 3.9775 - val_yolo_loss_layer_1_loss: 2.2546 - val_yolo_loss_layer_2_loss: 0.0349 - val_yolo_loss_layer_3_loss: 1.4898e-04\n",
      "Epoch 78/300\n",
      "306/306 [==============================] - 185s 605ms/step - loss: 2.8362 - yolo_loss_layer_1_loss: 1.1112 - yolo_loss_layer_2_loss: 0.0400 - yolo_loss_layer_3_loss: 1.5258e-04 - val_loss: 3.9265 - val_yolo_loss_layer_1_loss: 2.2118 - val_yolo_loss_layer_2_loss: 0.0329 - val_yolo_loss_layer_3_loss: 1.3160e-04\n",
      "Epoch 79/300\n",
      "306/306 [==============================] - 177s 577ms/step - loss: 2.8084 - yolo_loss_layer_1_loss: 1.0867 - yolo_loss_layer_2_loss: 0.0432 - yolo_loss_layer_3_loss: 1.4606e-04 - val_loss: 4.0517 - val_yolo_loss_layer_1_loss: 2.3436 - val_yolo_loss_layer_2_loss: 0.0328 - val_yolo_loss_layer_3_loss: 1.5502e-04\n",
      "Epoch 80/300\n",
      "306/306 [==============================] - 176s 576ms/step - loss: 2.7917 - yolo_loss_layer_1_loss: 1.0726 - yolo_loss_layer_2_loss: 0.0471 - yolo_loss_layer_3_loss: 1.4880e-04 - val_loss: 4.0017 - val_yolo_loss_layer_1_loss: 2.2961 - val_yolo_loss_layer_2_loss: 0.0369 - val_yolo_loss_layer_3_loss: 1.4868e-04\n",
      "Epoch 81/300\n",
      "306/306 [==============================] - 184s 601ms/step - loss: 2.8062 - yolo_loss_layer_1_loss: 1.0950 - yolo_loss_layer_2_loss: 0.0456 - yolo_loss_layer_3_loss: 1.5465e-04 - val_loss: 3.9081 - val_yolo_loss_layer_1_loss: 2.1952 - val_yolo_loss_layer_2_loss: 0.0501 - val_yolo_loss_layer_3_loss: 1.3676e-04\n",
      "Epoch 82/300\n",
      "306/306 [==============================] - 159s 518ms/step - loss: 2.7120 - yolo_loss_layer_1_loss: 1.0096 - yolo_loss_layer_2_loss: 0.0426 - yolo_loss_layer_3_loss: 1.3713e-04 - val_loss: 4.0635 - val_yolo_loss_layer_1_loss: 2.3673 - val_yolo_loss_layer_2_loss: 0.0396 - val_yolo_loss_layer_3_loss: 1.4781e-04\n",
      "Epoch 83/300\n",
      "306/306 [==============================] - 183s 599ms/step - loss: 2.6766 - yolo_loss_layer_1_loss: 0.9822 - yolo_loss_layer_2_loss: 0.0411 - yolo_loss_layer_3_loss: 1.5367e-04 - val_loss: 3.8249 - val_yolo_loss_layer_1_loss: 2.1393 - val_yolo_loss_layer_2_loss: 0.0355 - val_yolo_loss_layer_3_loss: 1.3870e-04\n",
      "Epoch 84/300\n",
      "306/306 [==============================] - 174s 567ms/step - loss: 2.6836 - yolo_loss_layer_1_loss: 0.9923 - yolo_loss_layer_2_loss: 0.0444 - yolo_loss_layer_3_loss: 1.4111e-04 - val_loss: 4.0104 - val_yolo_loss_layer_1_loss: 2.3333 - val_yolo_loss_layer_2_loss: 0.0334 - val_yolo_loss_layer_3_loss: 1.4319e-04\n",
      "Epoch 85/300\n",
      "306/306 [==============================] - 166s 544ms/step - loss: 2.6313 - yolo_loss_layer_1_loss: 0.9401 - yolo_loss_layer_2_loss: 0.0506 - yolo_loss_layer_3_loss: 1.4410e-04 - val_loss: 3.8621 - val_yolo_loss_layer_1_loss: 2.1892 - val_yolo_loss_layer_2_loss: 0.0356 - val_yolo_loss_layer_3_loss: 1.3834e-04\n",
      "Epoch 86/300\n",
      "306/306 [==============================] - 173s 565ms/step - loss: 2.6386 - yolo_loss_layer_1_loss: 0.9622 - yolo_loss_layer_2_loss: 0.0420 - yolo_loss_layer_3_loss: 1.4915e-04 - val_loss: 4.0955 - val_yolo_loss_layer_1_loss: 2.4258 - val_yolo_loss_layer_2_loss: 0.0384 - val_yolo_loss_layer_3_loss: 1.2490e-04\n",
      "Epoch 87/300\n",
      "306/306 [==============================] - 172s 562ms/step - loss: 2.5638 - yolo_loss_layer_1_loss: 0.8908 - yolo_loss_layer_2_loss: 0.0446 - yolo_loss_layer_3_loss: 1.4172e-04 - val_loss: 3.9221 - val_yolo_loss_layer_1_loss: 2.2650 - val_yolo_loss_layer_2_loss: 0.0318 - val_yolo_loss_layer_3_loss: 1.4158e-04\n",
      "Epoch 88/300\n",
      "306/306 [==============================] - 165s 538ms/step - loss: 2.5651 - yolo_loss_layer_1_loss: 0.8979 - yolo_loss_layer_2_loss: 0.0450 - yolo_loss_layer_3_loss: 1.4120e-04 - val_loss: 3.9821 - val_yolo_loss_layer_1_loss: 2.3264 - val_yolo_loss_layer_2_loss: 0.0365 - val_yolo_loss_layer_3_loss: 1.3045e-04\n",
      "Epoch 89/300\n",
      "306/306 [==============================] - 184s 602ms/step - loss: 2.6184 - yolo_loss_layer_1_loss: 0.9514 - yolo_loss_layer_2_loss: 0.0507 - yolo_loss_layer_3_loss: 1.5126e-04 - val_loss: 3.8540 - val_yolo_loss_layer_1_loss: 2.2099 - val_yolo_loss_layer_2_loss: 0.0308 - val_yolo_loss_layer_3_loss: 1.4454e-04\n",
      "Epoch 90/300\n",
      "306/306 [==============================] - 178s 583ms/step - loss: 2.5990 - yolo_loss_layer_1_loss: 0.9437 - yolo_loss_layer_2_loss: 0.0449 - yolo_loss_layer_3_loss: 1.4688e-04 - val_loss: 3.9362 - val_yolo_loss_layer_1_loss: 2.2937 - val_yolo_loss_layer_2_loss: 0.0350 - val_yolo_loss_layer_3_loss: 1.3181e-04\n",
      "Epoch 91/300\n",
      "306/306 [==============================] - 173s 565ms/step - loss: 2.5774 - yolo_loss_layer_1_loss: 0.9372 - yolo_loss_layer_2_loss: 0.0357 - yolo_loss_layer_3_loss: 1.4303e-04 - val_loss: 4.0710 - val_yolo_loss_layer_1_loss: 2.4349 - val_yolo_loss_layer_2_loss: 0.0344 - val_yolo_loss_layer_3_loss: 1.3484e-04\n",
      "Epoch 92/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 2.5394 - yolo_loss_layer_1_loss: 0.8935 - yolo_loss_layer_2_loss: 0.0470 - yolo_loss_layer_3_loss: 1.4485e-04 - val_loss: 4.0364 - val_yolo_loss_layer_1_loss: 2.4011 - val_yolo_loss_layer_2_loss: 0.0395 - val_yolo_loss_layer_3_loss: 1.3795e-04\n",
      "Epoch 93/300\n",
      "306/306 [==============================] - 167s 547ms/step - loss: 2.5304 - yolo_loss_layer_1_loss: 0.9015 - yolo_loss_layer_2_loss: 0.0361 - yolo_loss_layer_3_loss: 1.3884e-04 - val_loss: 4.1379 - val_yolo_loss_layer_1_loss: 2.5117 - val_yolo_loss_layer_2_loss: 0.0364 - val_yolo_loss_layer_3_loss: 1.2945e-04\n",
      "Epoch 94/300\n",
      "306/306 [==============================] - 176s 575ms/step - loss: 2.4890 - yolo_loss_layer_1_loss: 0.8579 - yolo_loss_layer_2_loss: 0.0442 - yolo_loss_layer_3_loss: 1.4439e-04 - val_loss: 3.8288 - val_yolo_loss_layer_1_loss: 2.2108 - val_yolo_loss_layer_2_loss: 0.0340 - val_yolo_loss_layer_3_loss: 1.3228e-04\n",
      "Epoch 95/300\n",
      "306/306 [==============================] - 183s 599ms/step - loss: 2.4699 - yolo_loss_layer_1_loss: 0.8503 - yolo_loss_layer_2_loss: 0.0385 - yolo_loss_layer_3_loss: 1.5177e-04 - val_loss: 4.0041 - val_yolo_loss_layer_1_loss: 2.3881 - val_yolo_loss_layer_2_loss: 0.0378 - val_yolo_loss_layer_3_loss: 1.3629e-04\n",
      "Epoch 96/300\n",
      "306/306 [==============================] - 182s 596ms/step - loss: 2.5147 - yolo_loss_layer_1_loss: 0.8943 - yolo_loss_layer_2_loss: 0.0452 - yolo_loss_layer_3_loss: 1.4416e-04 - val_loss: 3.8333 - val_yolo_loss_layer_1_loss: 2.2271 - val_yolo_loss_layer_2_loss: 0.0340 - val_yolo_loss_layer_3_loss: 1.1896e-04\n",
      "Epoch 97/300\n",
      "306/306 [==============================] - 166s 544ms/step - loss: 2.4868 - yolo_loss_layer_1_loss: 0.8706 - yolo_loss_layer_2_loss: 0.0472 - yolo_loss_layer_3_loss: 1.3452e-04 - val_loss: 3.9825 - val_yolo_loss_layer_1_loss: 2.3829 - val_yolo_loss_layer_2_loss: 0.0336 - val_yolo_loss_layer_3_loss: 1.1836e-04\n",
      "Epoch 98/300\n",
      "306/306 [==============================] - 188s 613ms/step - loss: 2.5049 - yolo_loss_layer_1_loss: 0.8958 - yolo_loss_layer_2_loss: 0.0462 - yolo_loss_layer_3_loss: 1.4274e-04 - val_loss: 3.9941 - val_yolo_loss_layer_1_loss: 2.3992 - val_yolo_loss_layer_2_loss: 0.0351 - val_yolo_loss_layer_3_loss: 1.1761e-04\n",
      "Epoch 99/300\n",
      "306/306 [==============================] - 190s 620ms/step - loss: 2.4007 - yolo_loss_layer_1_loss: 0.8053 - yolo_loss_layer_2_loss: 0.0385 - yolo_loss_layer_3_loss: 1.4375e-04 - val_loss: 3.8473 - val_yolo_loss_layer_1_loss: 2.2616 - val_yolo_loss_layer_2_loss: 0.0321 - val_yolo_loss_layer_3_loss: 1.3343e-04\n",
      "Epoch 100/300\n",
      "306/306 [==============================] - 182s 595ms/step - loss: 2.3979 - yolo_loss_layer_1_loss: 0.7979 - yolo_loss_layer_2_loss: 0.0494 - yolo_loss_layer_3_loss: 1.3847e-04 - val_loss: 4.0478 - val_yolo_loss_layer_1_loss: 2.4656 - val_yolo_loss_layer_2_loss: 0.0347 - val_yolo_loss_layer_3_loss: 1.3227e-04\n",
      "Epoch 101/300\n",
      "306/306 [==============================] - 183s 597ms/step - loss: 2.4052 - yolo_loss_layer_1_loss: 0.8161 - yolo_loss_layer_2_loss: 0.0445 - yolo_loss_layer_3_loss: 1.4014e-04 - val_loss: 3.7981 - val_yolo_loss_layer_1_loss: 2.2141 - val_yolo_loss_layer_2_loss: 0.0426 - val_yolo_loss_layer_3_loss: 1.2590e-04\n",
      "Epoch 102/300\n",
      "306/306 [==============================] - 191s 625ms/step - loss: 2.4423 - yolo_loss_layer_1_loss: 0.8625 - yolo_loss_layer_2_loss: 0.0411 - yolo_loss_layer_3_loss: 1.4426e-04 - val_loss: 3.8783 - val_yolo_loss_layer_1_loss: 2.3083 - val_yolo_loss_layer_2_loss: 0.0344 - val_yolo_loss_layer_3_loss: 1.1992e-04\n",
      "Epoch 103/300\n",
      "306/306 [==============================] - 185s 604ms/step - loss: 2.3399 - yolo_loss_layer_1_loss: 0.7618 - yolo_loss_layer_2_loss: 0.0455 - yolo_loss_layer_3_loss: 1.3833e-04 - val_loss: 3.8996 - val_yolo_loss_layer_1_loss: 2.3340 - val_yolo_loss_layer_2_loss: 0.0360 - val_yolo_loss_layer_3_loss: 1.3037e-04\n",
      "Epoch 104/300\n",
      "306/306 [==============================] - 183s 599ms/step - loss: 2.4123 - yolo_loss_layer_1_loss: 0.8397 - yolo_loss_layer_2_loss: 0.0460 - yolo_loss_layer_3_loss: 1.3700e-04 - val_loss: 4.0267 - val_yolo_loss_layer_1_loss: 2.4613 - val_yolo_loss_layer_2_loss: 0.0418 - val_yolo_loss_layer_3_loss: 1.4200e-04\n",
      "Epoch 105/300\n",
      "306/306 [==============================] - 195s 637ms/step - loss: 2.3601 - yolo_loss_layer_1_loss: 0.7931 - yolo_loss_layer_2_loss: 0.0461 - yolo_loss_layer_3_loss: 1.3817e-04 - val_loss: 4.0001 - val_yolo_loss_layer_1_loss: 2.4440 - val_yolo_loss_layer_2_loss: 0.0380 - val_yolo_loss_layer_3_loss: 1.5401e-04\n",
      "Epoch 106/300\n",
      "306/306 [==============================] - 180s 588ms/step - loss: 2.3220 - yolo_loss_layer_1_loss: 0.7716 - yolo_loss_layer_2_loss: 0.0355 - yolo_loss_layer_3_loss: 1.3812e-04 - val_loss: 3.8620 - val_yolo_loss_layer_1_loss: 2.3118 - val_yolo_loss_layer_2_loss: 0.0384 - val_yolo_loss_layer_3_loss: 1.2611e-04\n",
      "Epoch 107/300\n",
      "306/306 [==============================] - 200s 652ms/step - loss: 2.3622 - yolo_loss_layer_1_loss: 0.8130 - yolo_loss_layer_2_loss: 0.0403 - yolo_loss_layer_3_loss: 1.4728e-04 - val_loss: 3.8376 - val_yolo_loss_layer_1_loss: 2.2962 - val_yolo_loss_layer_2_loss: 0.0354 - val_yolo_loss_layer_3_loss: 1.3285e-04\n",
      "Epoch 108/300\n",
      "306/306 [==============================] - 185s 604ms/step - loss: 2.3783 - yolo_loss_layer_1_loss: 0.8320 - yolo_loss_layer_2_loss: 0.0431 - yolo_loss_layer_3_loss: 1.3461e-04 - val_loss: 3.8678 - val_yolo_loss_layer_1_loss: 2.3318 - val_yolo_loss_layer_2_loss: 0.0356 - val_yolo_loss_layer_3_loss: 1.4493e-04\n",
      "Epoch 109/300\n",
      "306/306 [==============================] - 184s 601ms/step - loss: 2.3394 - yolo_loss_layer_1_loss: 0.8029 - yolo_loss_layer_2_loss: 0.0391 - yolo_loss_layer_3_loss: 1.3912e-04 - val_loss: 3.9030 - val_yolo_loss_layer_1_loss: 2.3779 - val_yolo_loss_layer_2_loss: 0.0305 - val_yolo_loss_layer_3_loss: 1.2962e-04\n",
      "Epoch 110/300\n",
      "306/306 [==============================] - 172s 563ms/step - loss: 2.2668 - yolo_loss_layer_1_loss: 0.7387 - yolo_loss_layer_2_loss: 0.0367 - yolo_loss_layer_3_loss: 1.2878e-04 - val_loss: 3.9893 - val_yolo_loss_layer_1_loss: 2.4650 - val_yolo_loss_layer_2_loss: 0.0359 - val_yolo_loss_layer_3_loss: 1.4216e-04\n",
      "Epoch 111/300\n",
      "306/306 [==============================] - 178s 582ms/step - loss: 2.2800 - yolo_loss_layer_1_loss: 0.7447 - yolo_loss_layer_2_loss: 0.0499 - yolo_loss_layer_3_loss: 1.3217e-04 - val_loss: 3.8796 - val_yolo_loss_layer_1_loss: 2.3605 - val_yolo_loss_layer_2_loss: 0.0367 - val_yolo_loss_layer_3_loss: 1.4019e-04\n",
      "Epoch 112/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 2.1892 - yolo_loss_layer_1_loss: 0.6771 - yolo_loss_layer_2_loss: 0.0331 - yolo_loss_layer_3_loss: 1.3264e-04 - val_loss: 3.6488 - val_yolo_loss_layer_1_loss: 2.1372 - val_yolo_loss_layer_2_loss: 0.0355 - val_yolo_loss_layer_3_loss: 1.2226e-04\n",
      "Epoch 113/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 2.2210 - yolo_loss_layer_1_loss: 0.7072 - yolo_loss_layer_2_loss: 0.0407 - yolo_loss_layer_3_loss: 1.3467e-04 - val_loss: 3.9826 - val_yolo_loss_layer_1_loss: 2.4628 - val_yolo_loss_layer_2_loss: 0.0497 - val_yolo_loss_layer_3_loss: 1.1456e-04\n",
      "Epoch 114/300\n",
      "306/306 [==============================] - 173s 566ms/step - loss: 2.2460 - yolo_loss_layer_1_loss: 0.7337 - yolo_loss_layer_2_loss: 0.0451 - yolo_loss_layer_3_loss: 1.3424e-04 - val_loss: 3.8468 - val_yolo_loss_layer_1_loss: 2.3478 - val_yolo_loss_layer_2_loss: 0.0345 - val_yolo_loss_layer_3_loss: 1.1007e-04\n",
      "Epoch 115/300\n",
      "306/306 [==============================] - 178s 581ms/step - loss: 2.2294 - yolo_loss_layer_1_loss: 0.7192 - yolo_loss_layer_2_loss: 0.0485 - yolo_loss_layer_3_loss: 1.3740e-04 - val_loss: 3.9040 - val_yolo_loss_layer_1_loss: 2.4075 - val_yolo_loss_layer_2_loss: 0.0372 - val_yolo_loss_layer_3_loss: 1.1487e-04\n",
      "Epoch 116/300\n",
      "306/306 [==============================] - 172s 563ms/step - loss: 2.2092 - yolo_loss_layer_1_loss: 0.7097 - yolo_loss_layer_2_loss: 0.0429 - yolo_loss_layer_3_loss: 1.3646e-04 - val_loss: 3.7117 - val_yolo_loss_layer_1_loss: 2.2207 - val_yolo_loss_layer_2_loss: 0.0373 - val_yolo_loss_layer_3_loss: 1.0427e-04\n",
      "Epoch 117/300\n",
      "306/306 [==============================] - 185s 603ms/step - loss: 2.1993 - yolo_loss_layer_1_loss: 0.7078 - yolo_loss_layer_2_loss: 0.0406 - yolo_loss_layer_3_loss: 1.3385e-04 - val_loss: 3.8172 - val_yolo_loss_layer_1_loss: 2.3355 - val_yolo_loss_layer_2_loss: 0.0336 - val_yolo_loss_layer_3_loss: 1.5132e-04\n",
      "Epoch 118/300\n",
      "306/306 [==============================] - 165s 539ms/step - loss: 2.2958 - yolo_loss_layer_1_loss: 0.8111 - yolo_loss_layer_2_loss: 0.0393 - yolo_loss_layer_3_loss: 1.2816e-04 - val_loss: 3.7062 - val_yolo_loss_layer_1_loss: 2.2312 - val_yolo_loss_layer_2_loss: 0.0324 - val_yolo_loss_layer_3_loss: 1.2158e-04\n",
      "Epoch 119/300\n",
      "306/306 [==============================] - 169s 553ms/step - loss: 2.1469 - yolo_loss_layer_1_loss: 0.6688 - yolo_loss_layer_2_loss: 0.0383 - yolo_loss_layer_3_loss: 1.3191e-04 - val_loss: 3.6496 - val_yolo_loss_layer_1_loss: 2.1756 - val_yolo_loss_layer_2_loss: 0.0370 - val_yolo_loss_layer_3_loss: 1.2038e-04\n",
      "Epoch 120/300\n",
      "306/306 [==============================] - 187s 609ms/step - loss: 2.1295 - yolo_loss_layer_1_loss: 0.6634 - yolo_loss_layer_2_loss: 0.0317 - yolo_loss_layer_3_loss: 1.3887e-04 - val_loss: 3.8267 - val_yolo_loss_layer_1_loss: 2.3597 - val_yolo_loss_layer_2_loss: 0.0355 - val_yolo_loss_layer_3_loss: 1.3702e-04\n",
      "Epoch 121/300\n",
      "306/306 [==============================] - 149s 488ms/step - loss: 2.1724 - yolo_loss_layer_1_loss: 0.7052 - yolo_loss_layer_2_loss: 0.0384 - yolo_loss_layer_3_loss: 1.2249e-04 - val_loss: 3.7708 - val_yolo_loss_layer_1_loss: 2.3113 - val_yolo_loss_layer_2_loss: 0.0334 - val_yolo_loss_layer_3_loss: 1.0902e-04\n",
      "Epoch 122/300\n",
      "306/306 [==============================] - 184s 600ms/step - loss: 2.1512 - yolo_loss_layer_1_loss: 0.6822 - yolo_loss_layer_2_loss: 0.0455 - yolo_loss_layer_3_loss: 1.3891e-04 - val_loss: 3.7632 - val_yolo_loss_layer_1_loss: 2.3079 - val_yolo_loss_layer_2_loss: 0.0344 - val_yolo_loss_layer_3_loss: 1.4085e-04\n",
      "Epoch 123/300\n",
      "306/306 [==============================] - 169s 552ms/step - loss: 2.1934 - yolo_loss_layer_1_loss: 0.7369 - yolo_loss_layer_2_loss: 0.0384 - yolo_loss_layer_3_loss: 1.2726e-04 - val_loss: 3.7468 - val_yolo_loss_layer_1_loss: 2.2950 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 1.3002e-04\n",
      "Epoch 124/300\n",
      "306/306 [==============================] - 156s 511ms/step - loss: 2.1405 - yolo_loss_layer_1_loss: 0.6864 - yolo_loss_layer_2_loss: 0.0411 - yolo_loss_layer_3_loss: 1.2418e-04 - val_loss: 3.7243 - val_yolo_loss_layer_1_loss: 2.2771 - val_yolo_loss_layer_2_loss: 0.0367 - val_yolo_loss_layer_3_loss: 1.1911e-04\n",
      "Epoch 125/300\n",
      "306/306 [==============================] - 168s 548ms/step - loss: 2.0783 - yolo_loss_layer_1_loss: 0.6322 - yolo_loss_layer_2_loss: 0.0384 - yolo_loss_layer_3_loss: 1.2942e-04 - val_loss: 3.9259 - val_yolo_loss_layer_1_loss: 2.4840 - val_yolo_loss_layer_2_loss: 0.0368 - val_yolo_loss_layer_3_loss: 1.2632e-04\n",
      "Epoch 126/300\n",
      "306/306 [==============================] - 185s 606ms/step - loss: 2.1015 - yolo_loss_layer_1_loss: 0.6538 - yolo_loss_layer_2_loss: 0.0455 - yolo_loss_layer_3_loss: 1.4268e-04 - val_loss: 3.7281 - val_yolo_loss_layer_1_loss: 2.2962 - val_yolo_loss_layer_2_loss: 0.0324 - val_yolo_loss_layer_3_loss: 1.2897e-04\n",
      "Epoch 127/300\n",
      "306/306 [==============================] - 167s 544ms/step - loss: 2.0341 - yolo_loss_layer_1_loss: 0.5967 - yolo_loss_layer_2_loss: 0.0408 - yolo_loss_layer_3_loss: 1.2879e-04 - val_loss: 3.7209 - val_yolo_loss_layer_1_loss: 2.2944 - val_yolo_loss_layer_2_loss: 0.0328 - val_yolo_loss_layer_3_loss: 1.3166e-04\n",
      "Epoch 128/300\n",
      "306/306 [==============================] - 171s 558ms/step - loss: 2.0686 - yolo_loss_layer_1_loss: 0.6381 - yolo_loss_layer_2_loss: 0.0396 - yolo_loss_layer_3_loss: 1.3132e-04 - val_loss: 3.8868 - val_yolo_loss_layer_1_loss: 2.4658 - val_yolo_loss_layer_2_loss: 0.0329 - val_yolo_loss_layer_3_loss: 1.2493e-04\n",
      "Epoch 129/300\n",
      "306/306 [==============================] - 175s 571ms/step - loss: 2.0422 - yolo_loss_layer_1_loss: 0.6166 - yolo_loss_layer_2_loss: 0.0402 - yolo_loss_layer_3_loss: 1.3629e-04 - val_loss: 3.9240 - val_yolo_loss_layer_1_loss: 2.5059 - val_yolo_loss_layer_2_loss: 0.0354 - val_yolo_loss_layer_3_loss: 1.2047e-04\n",
      "Epoch 130/300\n",
      "306/306 [==============================] - 173s 565ms/step - loss: 2.0800 - yolo_loss_layer_1_loss: 0.6577 - yolo_loss_layer_2_loss: 0.0423 - yolo_loss_layer_3_loss: 1.3532e-04 - val_loss: 3.8058 - val_yolo_loss_layer_1_loss: 2.3945 - val_yolo_loss_layer_2_loss: 0.0342 - val_yolo_loss_layer_3_loss: 1.2818e-04\n",
      "Epoch 131/300\n",
      "306/306 [==============================] - 173s 565ms/step - loss: 2.0395 - yolo_loss_layer_1_loss: 0.6285 - yolo_loss_layer_2_loss: 0.0367 - yolo_loss_layer_3_loss: 1.3330e-04 - val_loss: 3.6009 - val_yolo_loss_layer_1_loss: 2.1955 - val_yolo_loss_layer_2_loss: 0.0340 - val_yolo_loss_layer_3_loss: 1.2776e-04\n",
      "Epoch 132/300\n",
      "306/306 [==============================] - 164s 535ms/step - loss: 2.1095 - yolo_loss_layer_1_loss: 0.6968 - yolo_loss_layer_2_loss: 0.0442 - yolo_loss_layer_3_loss: 1.2638e-04 - val_loss: 3.7294 - val_yolo_loss_layer_1_loss: 2.3209 - val_yolo_loss_layer_2_loss: 0.0425 - val_yolo_loss_layer_3_loss: 1.1404e-04\n",
      "Epoch 133/300\n",
      "306/306 [==============================] - 172s 563ms/step - loss: 2.0022 - yolo_loss_layer_1_loss: 0.5975 - yolo_loss_layer_2_loss: 0.0415 - yolo_loss_layer_3_loss: 1.3102e-04 - val_loss: 3.7483 - val_yolo_loss_layer_1_loss: 2.3555 - val_yolo_loss_layer_2_loss: 0.0325 - val_yolo_loss_layer_3_loss: 1.3223e-04\n",
      "Epoch 134/300\n",
      "306/306 [==============================] - 174s 567ms/step - loss: 2.0614 - yolo_loss_layer_1_loss: 0.6622 - yolo_loss_layer_2_loss: 0.0414 - yolo_loss_layer_3_loss: 1.3401e-04 - val_loss: 3.6516 - val_yolo_loss_layer_1_loss: 2.2575 - val_yolo_loss_layer_2_loss: 0.0389 - val_yolo_loss_layer_3_loss: 1.2180e-04\n",
      "Epoch 135/300\n",
      "306/306 [==============================] - 177s 577ms/step - loss: 2.0068 - yolo_loss_layer_1_loss: 0.6199 - yolo_loss_layer_2_loss: 0.0344 - yolo_loss_layer_3_loss: 1.2778e-04 - val_loss: 3.7751 - val_yolo_loss_layer_1_loss: 2.3919 - val_yolo_loss_layer_2_loss: 0.0335 - val_yolo_loss_layer_3_loss: 1.4111e-04\n",
      "Epoch 136/300\n",
      "306/306 [==============================] - 163s 532ms/step - loss: 2.1042 - yolo_loss_layer_1_loss: 0.7219 - yolo_loss_layer_2_loss: 0.0350 - yolo_loss_layer_3_loss: 1.2591e-04 - val_loss: 3.7347 - val_yolo_loss_layer_1_loss: 2.3567 - val_yolo_loss_layer_2_loss: 0.0334 - val_yolo_loss_layer_3_loss: 1.2979e-04\n",
      "Epoch 137/300\n",
      "306/306 [==============================] - 171s 560ms/step - loss: 2.0021 - yolo_loss_layer_1_loss: 0.6171 - yolo_loss_layer_2_loss: 0.0429 - yolo_loss_layer_3_loss: 1.3202e-04 - val_loss: 3.6495 - val_yolo_loss_layer_1_loss: 2.2712 - val_yolo_loss_layer_2_loss: 0.0388 - val_yolo_loss_layer_3_loss: 1.2689e-04\n",
      "Epoch 138/300\n",
      "306/306 [==============================] - 178s 581ms/step - loss: 1.9537 - yolo_loss_layer_1_loss: 0.5810 - yolo_loss_layer_2_loss: 0.0358 - yolo_loss_layer_3_loss: 1.3441e-04 - val_loss: 3.8397 - val_yolo_loss_layer_1_loss: 2.4587 - val_yolo_loss_layer_2_loss: 0.0468 - val_yolo_loss_layer_3_loss: 1.2658e-04\n",
      "Epoch 139/300\n",
      "306/306 [==============================] - 171s 558ms/step - loss: 1.9589 - yolo_loss_layer_1_loss: 0.5909 - yolo_loss_layer_2_loss: 0.0366 - yolo_loss_layer_3_loss: 1.3475e-04 - val_loss: 3.7179 - val_yolo_loss_layer_1_loss: 2.3538 - val_yolo_loss_layer_2_loss: 0.0353 - val_yolo_loss_layer_3_loss: 1.1521e-04\n",
      "Epoch 140/300\n",
      "306/306 [==============================] - 179s 585ms/step - loss: 1.9240 - yolo_loss_layer_1_loss: 0.5674 - yolo_loss_layer_2_loss: 0.0302 - yolo_loss_layer_3_loss: 1.3761e-04 - val_loss: 3.7285 - val_yolo_loss_layer_1_loss: 2.3705 - val_yolo_loss_layer_2_loss: 0.0342 - val_yolo_loss_layer_3_loss: 1.3133e-04\n",
      "Epoch 141/300\n",
      "306/306 [==============================] - 180s 587ms/step - loss: 1.9135 - yolo_loss_layer_1_loss: 0.5564 - yolo_loss_layer_2_loss: 0.0360 - yolo_loss_layer_3_loss: 1.3723e-04 - val_loss: 3.5727 - val_yolo_loss_layer_1_loss: 2.2187 - val_yolo_loss_layer_2_loss: 0.0354 - val_yolo_loss_layer_3_loss: 1.2279e-04\n",
      "Epoch 142/300\n",
      "306/306 [==============================] - 167s 547ms/step - loss: 1.9554 - yolo_loss_layer_1_loss: 0.5990 - yolo_loss_layer_2_loss: 0.0403 - yolo_loss_layer_3_loss: 1.3166e-04 - val_loss: 3.5676 - val_yolo_loss_layer_1_loss: 2.2208 - val_yolo_loss_layer_2_loss: 0.0333 - val_yolo_loss_layer_3_loss: 1.1684e-04\n",
      "Epoch 143/300\n",
      "306/306 [==============================] - 175s 573ms/step - loss: 1.9092 - yolo_loss_layer_1_loss: 0.5634 - yolo_loss_layer_2_loss: 0.0348 - yolo_loss_layer_3_loss: 1.2835e-04 - val_loss: 3.7770 - val_yolo_loss_layer_1_loss: 2.4317 - val_yolo_loss_layer_2_loss: 0.0369 - val_yolo_loss_layer_3_loss: 1.4802e-04\n",
      "Epoch 144/300\n",
      "306/306 [==============================] - 183s 597ms/step - loss: 1.9001 - yolo_loss_layer_1_loss: 0.5588 - yolo_loss_layer_2_loss: 0.0356 - yolo_loss_layer_3_loss: 1.3860e-04 - val_loss: 3.8423 - val_yolo_loss_layer_1_loss: 2.5060 - val_yolo_loss_layer_2_loss: 0.0333 - val_yolo_loss_layer_3_loss: 1.3376e-04\n",
      "Epoch 145/300\n",
      "306/306 [==============================] - 163s 533ms/step - loss: 1.9605 - yolo_loss_layer_1_loss: 0.6241 - yolo_loss_layer_2_loss: 0.0359 - yolo_loss_layer_3_loss: 1.2809e-04 - val_loss: 3.7791 - val_yolo_loss_layer_1_loss: 2.4396 - val_yolo_loss_layer_2_loss: 0.0415 - val_yolo_loss_layer_3_loss: 1.2412e-04\n",
      "Epoch 146/300\n",
      "306/306 [==============================] - 168s 549ms/step - loss: 1.9134 - yolo_loss_layer_1_loss: 0.5745 - yolo_loss_layer_2_loss: 0.0435 - yolo_loss_layer_3_loss: 1.3335e-04 - val_loss: 3.4033 - val_yolo_loss_layer_1_loss: 2.0769 - val_yolo_loss_layer_2_loss: 0.0338 - val_yolo_loss_layer_3_loss: 1.1675e-04\n",
      "Epoch 147/300\n",
      "306/306 [==============================] - 174s 570ms/step - loss: 1.8714 - yolo_loss_layer_1_loss: 0.5441 - yolo_loss_layer_2_loss: 0.0373 - yolo_loss_layer_3_loss: 1.3435e-04 - val_loss: 3.6643 - val_yolo_loss_layer_1_loss: 2.3415 - val_yolo_loss_layer_2_loss: 0.0354 - val_yolo_loss_layer_3_loss: 1.1064e-04\n",
      "Epoch 148/300\n",
      "306/306 [==============================] - 176s 575ms/step - loss: 1.8530 - yolo_loss_layer_1_loss: 0.5250 - yolo_loss_layer_2_loss: 0.0433 - yolo_loss_layer_3_loss: 1.3636e-04 - val_loss: 3.7200 - val_yolo_loss_layer_1_loss: 2.4033 - val_yolo_loss_layer_2_loss: 0.0346 - val_yolo_loss_layer_3_loss: 1.1655e-04\n",
      "Epoch 149/300\n",
      "306/306 [==============================] - 157s 514ms/step - loss: 1.9032 - yolo_loss_layer_1_loss: 0.5833 - yolo_loss_layer_2_loss: 0.0404 - yolo_loss_layer_3_loss: 1.2540e-04 - val_loss: 3.5346 - val_yolo_loss_layer_1_loss: 2.2238 - val_yolo_loss_layer_2_loss: 0.0338 - val_yolo_loss_layer_3_loss: 1.1682e-04\n",
      "Epoch 150/300\n",
      "306/306 [==============================] - 177s 578ms/step - loss: 1.8562 - yolo_loss_layer_1_loss: 0.5349 - yolo_loss_layer_2_loss: 0.0470 - yolo_loss_layer_3_loss: 1.3030e-04 - val_loss: 3.7758 - val_yolo_loss_layer_1_loss: 2.4676 - val_yolo_loss_layer_2_loss: 0.0365 - val_yolo_loss_layer_3_loss: 1.3495e-04\n",
      "Epoch 151/300\n",
      "306/306 [==============================] - 160s 522ms/step - loss: 1.8293 - yolo_loss_layer_1_loss: 0.5196 - yolo_loss_layer_2_loss: 0.0405 - yolo_loss_layer_3_loss: 1.2656e-04 - val_loss: 3.5859 - val_yolo_loss_layer_1_loss: 2.2806 - val_yolo_loss_layer_2_loss: 0.0389 - val_yolo_loss_layer_3_loss: 1.1864e-04\n",
      "Epoch 152/300\n",
      "306/306 [==============================] - 171s 559ms/step - loss: 1.8457 - yolo_loss_layer_1_loss: 0.5427 - yolo_loss_layer_2_loss: 0.0392 - yolo_loss_layer_3_loss: 1.3414e-04 - val_loss: 3.5851 - val_yolo_loss_layer_1_loss: 2.2852 - val_yolo_loss_layer_2_loss: 0.0387 - val_yolo_loss_layer_3_loss: 1.0881e-04\n",
      "Epoch 153/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 1.8203 - yolo_loss_layer_1_loss: 0.5191 - yolo_loss_layer_2_loss: 0.0427 - yolo_loss_layer_3_loss: 1.3155e-04 - val_loss: 3.6168 - val_yolo_loss_layer_1_loss: 2.3251 - val_yolo_loss_layer_2_loss: 0.0358 - val_yolo_loss_layer_3_loss: 1.3158e-04\n",
      "Epoch 154/300\n",
      "306/306 [==============================] - 165s 540ms/step - loss: 1.8089 - yolo_loss_layer_1_loss: 0.5161 - yolo_loss_layer_2_loss: 0.0394 - yolo_loss_layer_3_loss: 1.2328e-04 - val_loss: 3.6943 - val_yolo_loss_layer_1_loss: 2.4090 - val_yolo_loss_layer_2_loss: 0.0346 - val_yolo_loss_layer_3_loss: 1.2844e-04\n",
      "Epoch 155/300\n",
      "306/306 [==============================] - 178s 581ms/step - loss: 1.8205 - yolo_loss_layer_1_loss: 0.5335 - yolo_loss_layer_2_loss: 0.0388 - yolo_loss_layer_3_loss: 1.3504e-04 - val_loss: 3.6003 - val_yolo_loss_layer_1_loss: 2.3179 - val_yolo_loss_layer_2_loss: 0.0367 - val_yolo_loss_layer_3_loss: 1.2774e-04\n",
      "Epoch 156/300\n",
      "306/306 [==============================] - 179s 583ms/step - loss: 1.7668 - yolo_loss_layer_1_loss: 0.4801 - yolo_loss_layer_2_loss: 0.0437 - yolo_loss_layer_3_loss: 1.3639e-04 - val_loss: 3.4373 - val_yolo_loss_layer_1_loss: 2.1606 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 1.2188e-04\n",
      "Epoch 157/300\n",
      "306/306 [==============================] - 164s 536ms/step - loss: 1.7877 - yolo_loss_layer_1_loss: 0.5140 - yolo_loss_layer_2_loss: 0.0357 - yolo_loss_layer_3_loss: 1.2817e-04 - val_loss: 3.6061 - val_yolo_loss_layer_1_loss: 2.3350 - val_yolo_loss_layer_2_loss: 0.0357 - val_yolo_loss_layer_3_loss: 1.2249e-04\n",
      "Epoch 158/300\n",
      "306/306 [==============================] - 167s 547ms/step - loss: 1.7562 - yolo_loss_layer_1_loss: 0.4919 - yolo_loss_layer_2_loss: 0.0315 - yolo_loss_layer_3_loss: 1.3117e-04 - val_loss: 3.4359 - val_yolo_loss_layer_1_loss: 2.1704 - val_yolo_loss_layer_2_loss: 0.0353 - val_yolo_loss_layer_3_loss: 1.2594e-04\n",
      "Epoch 159/300\n",
      "306/306 [==============================] - 181s 592ms/step - loss: 1.8389 - yolo_loss_layer_1_loss: 0.5686 - yolo_loss_layer_2_loss: 0.0425 - yolo_loss_layer_3_loss: 1.3615e-04 - val_loss: 3.4974 - val_yolo_loss_layer_1_loss: 2.2335 - val_yolo_loss_layer_2_loss: 0.0386 - val_yolo_loss_layer_3_loss: 1.3157e-04\n",
      "Epoch 160/300\n",
      "306/306 [==============================] - 175s 572ms/step - loss: 1.7638 - yolo_loss_layer_1_loss: 0.4973 - yolo_loss_layer_2_loss: 0.0437 - yolo_loss_layer_3_loss: 1.3680e-04 - val_loss: 3.5351 - val_yolo_loss_layer_1_loss: 2.2797 - val_yolo_loss_layer_2_loss: 0.0349 - val_yolo_loss_layer_3_loss: 1.1617e-04\n",
      "Epoch 161/300\n",
      "306/306 [==============================] - 166s 542ms/step - loss: 1.7819 - yolo_loss_layer_1_loss: 0.5194 - yolo_loss_layer_2_loss: 0.0446 - yolo_loss_layer_3_loss: 1.2846e-04 - val_loss: 3.6130 - val_yolo_loss_layer_1_loss: 2.3616 - val_yolo_loss_layer_2_loss: 0.0359 - val_yolo_loss_layer_3_loss: 1.2465e-04\n",
      "Epoch 162/300\n",
      "306/306 [==============================] - 180s 587ms/step - loss: 1.7684 - yolo_loss_layer_1_loss: 0.5136 - yolo_loss_layer_2_loss: 0.0418 - yolo_loss_layer_3_loss: 1.3490e-04 - val_loss: 3.5951 - val_yolo_loss_layer_1_loss: 2.3475 - val_yolo_loss_layer_2_loss: 0.0370 - val_yolo_loss_layer_3_loss: 1.3350e-04\n",
      "Epoch 163/300\n",
      "306/306 [==============================] - 172s 561ms/step - loss: 1.7366 - yolo_loss_layer_1_loss: 0.4915 - yolo_loss_layer_2_loss: 0.0371 - yolo_loss_layer_3_loss: 1.3075e-04 - val_loss: 3.5546 - val_yolo_loss_layer_1_loss: 2.3150 - val_yolo_loss_layer_2_loss: 0.0342 - val_yolo_loss_layer_3_loss: 1.1857e-04\n",
      "Epoch 164/300\n",
      "306/306 [==============================] - 172s 564ms/step - loss: 1.7624 - yolo_loss_layer_1_loss: 0.5157 - yolo_loss_layer_2_loss: 0.0437 - yolo_loss_layer_3_loss: 1.3212e-04 - val_loss: 3.5410 - val_yolo_loss_layer_1_loss: 2.3075 - val_yolo_loss_layer_2_loss: 0.0330 - val_yolo_loss_layer_3_loss: 1.2173e-04\n",
      "Epoch 165/300\n",
      "306/306 [==============================] - 164s 536ms/step - loss: 1.7122 - yolo_loss_layer_1_loss: 0.4789 - yolo_loss_layer_2_loss: 0.0353 - yolo_loss_layer_3_loss: 1.2187e-04 - val_loss: 3.4427 - val_yolo_loss_layer_1_loss: 2.2109 - val_yolo_loss_layer_2_loss: 0.0365 - val_yolo_loss_layer_3_loss: 1.2852e-04\n",
      "Epoch 166/300\n",
      "306/306 [==============================] - 162s 530ms/step - loss: 1.7302 - yolo_loss_layer_1_loss: 0.4990 - yolo_loss_layer_2_loss: 0.0382 - yolo_loss_layer_3_loss: 1.2502e-04 - val_loss: 3.3897 - val_yolo_loss_layer_1_loss: 2.1652 - val_yolo_loss_layer_2_loss: 0.0340 - val_yolo_loss_layer_3_loss: 1.2367e-04\n",
      "Epoch 167/300\n",
      "306/306 [==============================] - 161s 525ms/step - loss: 1.6762 - yolo_loss_layer_1_loss: 0.4543 - yolo_loss_layer_2_loss: 0.0341 - yolo_loss_layer_3_loss: 1.2325e-04 - val_loss: 3.5152 - val_yolo_loss_layer_1_loss: 2.2970 - val_yolo_loss_layer_2_loss: 0.0332 - val_yolo_loss_layer_3_loss: 1.2503e-04\n",
      "Epoch 168/300\n",
      "306/306 [==============================] - 177s 579ms/step - loss: 1.7083 - yolo_loss_layer_1_loss: 0.4871 - yolo_loss_layer_2_loss: 0.0386 - yolo_loss_layer_3_loss: 1.3179e-04 - val_loss: 3.6614 - val_yolo_loss_layer_1_loss: 2.4279 - val_yolo_loss_layer_2_loss: 0.0535 - val_yolo_loss_layer_3_loss: 1.1929e-04\n",
      "Epoch 169/300\n",
      "306/306 [==============================] - 171s 559ms/step - loss: 1.6842 - yolo_loss_layer_1_loss: 0.4691 - yolo_loss_layer_2_loss: 0.0378 - yolo_loss_layer_3_loss: 1.2854e-04 - val_loss: 3.5898 - val_yolo_loss_layer_1_loss: 2.3811 - val_yolo_loss_layer_2_loss: 0.0339 - val_yolo_loss_layer_3_loss: 1.3392e-04\n",
      "Epoch 170/300\n",
      "306/306 [==============================] - 164s 537ms/step - loss: 1.7487 - yolo_loss_layer_1_loss: 0.5409 - yolo_loss_layer_2_loss: 0.0353 - yolo_loss_layer_3_loss: 1.2628e-04 - val_loss: 3.4593 - val_yolo_loss_layer_1_loss: 2.2544 - val_yolo_loss_layer_2_loss: 0.0350 - val_yolo_loss_layer_3_loss: 1.2233e-04\n",
      "Epoch 171/300\n",
      "306/306 [==============================] - 183s 598ms/step - loss: 1.6781 - yolo_loss_layer_1_loss: 0.4671 - yolo_loss_layer_2_loss: 0.0434 - yolo_loss_layer_3_loss: 1.3586e-04 - val_loss: 3.6529 - val_yolo_loss_layer_1_loss: 2.4538 - val_yolo_loss_layer_2_loss: 0.0341 - val_yolo_loss_layer_3_loss: 1.2974e-04\n",
      "Epoch 172/300\n",
      "306/306 [==============================] - 158s 517ms/step - loss: 1.6637 - yolo_loss_layer_1_loss: 0.4624 - yolo_loss_layer_2_loss: 0.0388 - yolo_loss_layer_3_loss: 1.2238e-04 - val_loss: 3.4817 - val_yolo_loss_layer_1_loss: 2.2881 - val_yolo_loss_layer_2_loss: 0.0337 - val_yolo_loss_layer_3_loss: 1.1919e-04\n",
      "Epoch 173/300\n",
      "306/306 [==============================] - 161s 525ms/step - loss: 1.6809 - yolo_loss_layer_1_loss: 0.4835 - yolo_loss_layer_2_loss: 0.0400 - yolo_loss_layer_3_loss: 1.2487e-04 - val_loss: 3.5234 - val_yolo_loss_layer_1_loss: 2.3253 - val_yolo_loss_layer_2_loss: 0.0433 - val_yolo_loss_layer_3_loss: 1.1524e-04\n",
      "Epoch 174/300\n",
      "306/306 [==============================] - 184s 601ms/step - loss: 1.6395 - yolo_loss_layer_1_loss: 0.4517 - yolo_loss_layer_2_loss: 0.0354 - yolo_loss_layer_3_loss: 1.3659e-04 - val_loss: 3.4203 - val_yolo_loss_layer_1_loss: 2.2362 - val_yolo_loss_layer_2_loss: 0.0340 - val_yolo_loss_layer_3_loss: 1.2900e-04\n",
      "Epoch 175/300\n",
      "306/306 [==============================] - 173s 567ms/step - loss: 1.6632 - yolo_loss_layer_1_loss: 0.4707 - yolo_loss_layer_2_loss: 0.0447 - yolo_loss_layer_3_loss: 1.3064e-04 - val_loss: 3.5592 - val_yolo_loss_layer_1_loss: 2.3785 - val_yolo_loss_layer_2_loss: 0.0351 - val_yolo_loss_layer_3_loss: 1.2794e-04\n",
      "Epoch 176/300\n",
      "306/306 [==============================] - 153s 502ms/step - loss: 1.6138 - yolo_loss_layer_1_loss: 0.4326 - yolo_loss_layer_2_loss: 0.0382 - yolo_loss_layer_3_loss: 1.1840e-04 - val_loss: 3.5996 - val_yolo_loss_layer_1_loss: 2.4247 - val_yolo_loss_layer_2_loss: 0.0344 - val_yolo_loss_layer_3_loss: 1.1729e-04\n",
      "Epoch 177/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 1.6227 - yolo_loss_layer_1_loss: 0.4465 - yolo_loss_layer_2_loss: 0.0383 - yolo_loss_layer_3_loss: 1.2956e-04 - val_loss: 3.5735 - val_yolo_loss_layer_1_loss: 2.4001 - val_yolo_loss_layer_2_loss: 0.0377 - val_yolo_loss_layer_3_loss: 1.3340e-04\n",
      "Epoch 178/300\n",
      "306/306 [==============================] - 174s 570ms/step - loss: 1.6104 - yolo_loss_layer_1_loss: 0.4389 - yolo_loss_layer_2_loss: 0.0382 - yolo_loss_layer_3_loss: 1.3181e-04 - val_loss: 3.4410 - val_yolo_loss_layer_1_loss: 2.2730 - val_yolo_loss_layer_2_loss: 0.0370 - val_yolo_loss_layer_3_loss: 1.3185e-04\n",
      "Epoch 179/300\n",
      "306/306 [==============================] - 179s 585ms/step - loss: 1.6364 - yolo_loss_layer_1_loss: 0.4669 - yolo_loss_layer_2_loss: 0.0409 - yolo_loss_layer_3_loss: 1.3186e-04 - val_loss: 3.5169 - val_yolo_loss_layer_1_loss: 2.3529 - val_yolo_loss_layer_2_loss: 0.0377 - val_yolo_loss_layer_3_loss: 1.2924e-04\n",
      "Epoch 180/300\n",
      "306/306 [==============================] - 173s 566ms/step - loss: 1.6202 - yolo_loss_layer_1_loss: 0.4524 - yolo_loss_layer_2_loss: 0.0439 - yolo_loss_layer_3_loss: 1.2736e-04 - val_loss: 3.5264 - val_yolo_loss_layer_1_loss: 2.3705 - val_yolo_loss_layer_2_loss: 0.0345 - val_yolo_loss_layer_3_loss: 1.2831e-04\n",
      "Epoch 181/300\n",
      "306/306 [==============================] - 161s 527ms/step - loss: 1.5991 - yolo_loss_layer_1_loss: 0.4387 - yolo_loss_layer_2_loss: 0.0414 - yolo_loss_layer_3_loss: 1.2838e-04 - val_loss: 3.2900 - val_yolo_loss_layer_1_loss: 2.1289 - val_yolo_loss_layer_2_loss: 0.0447 - val_yolo_loss_layer_3_loss: 1.0957e-04\n",
      "Epoch 182/300\n",
      "306/306 [==============================] - 165s 541ms/step - loss: 1.5804 - yolo_loss_layer_1_loss: 0.4283 - yolo_loss_layer_2_loss: 0.0381 - yolo_loss_layer_3_loss: 1.2435e-04 - val_loss: 3.5989 - val_yolo_loss_layer_1_loss: 2.4437 - val_yolo_loss_layer_2_loss: 0.0437 - val_yolo_loss_layer_3_loss: 1.2545e-04\n",
      "Epoch 183/300\n",
      "306/306 [==============================] - 181s 593ms/step - loss: 1.5886 - yolo_loss_layer_1_loss: 0.4429 - yolo_loss_layer_2_loss: 0.0366 - yolo_loss_layer_3_loss: 1.3543e-04 - val_loss: 3.4420 - val_yolo_loss_layer_1_loss: 2.2982 - val_yolo_loss_layer_2_loss: 0.0369 - val_yolo_loss_layer_3_loss: 1.2032e-04\n",
      "Epoch 184/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 1.5749 - yolo_loss_layer_1_loss: 0.4278 - yolo_loss_layer_2_loss: 0.0425 - yolo_loss_layer_3_loss: 1.3214e-04 - val_loss: 3.4541 - val_yolo_loss_layer_1_loss: 2.3140 - val_yolo_loss_layer_2_loss: 0.0378 - val_yolo_loss_layer_3_loss: 1.1753e-04\n",
      "Epoch 185/300\n",
      "306/306 [==============================] - 162s 529ms/step - loss: 1.6164 - yolo_loss_layer_1_loss: 0.4744 - yolo_loss_layer_2_loss: 0.0421 - yolo_loss_layer_3_loss: 1.2381e-04 - val_loss: 3.4049 - val_yolo_loss_layer_1_loss: 2.2718 - val_yolo_loss_layer_2_loss: 0.0356 - val_yolo_loss_layer_3_loss: 1.1738e-04\n",
      "Epoch 186/300\n",
      "306/306 [==============================] - 176s 575ms/step - loss: 1.5823 - yolo_loss_layer_1_loss: 0.4545 - yolo_loss_layer_2_loss: 0.0326 - yolo_loss_layer_3_loss: 1.3106e-04 - val_loss: 3.4730 - val_yolo_loss_layer_1_loss: 2.3454 - val_yolo_loss_layer_2_loss: 0.0349 - val_yolo_loss_layer_3_loss: 1.1090e-04\n",
      "Epoch 187/300\n",
      "306/306 [==============================] - 159s 518ms/step - loss: 1.5987 - yolo_loss_layer_1_loss: 0.4703 - yolo_loss_layer_2_loss: 0.0378 - yolo_loss_layer_3_loss: 1.1687e-04 - val_loss: 3.6022 - val_yolo_loss_layer_1_loss: 2.4748 - val_yolo_loss_layer_2_loss: 0.0393 - val_yolo_loss_layer_3_loss: 1.3736e-04\n",
      "Epoch 188/300\n",
      "306/306 [==============================] - 179s 585ms/step - loss: 1.5706 - yolo_loss_layer_1_loss: 0.4462 - yolo_loss_layer_2_loss: 0.0385 - yolo_loss_layer_3_loss: 1.3287e-04 - val_loss: 3.4005 - val_yolo_loss_layer_1_loss: 2.2825 - val_yolo_loss_layer_2_loss: 0.0343 - val_yolo_loss_layer_3_loss: 1.3065e-04\n",
      "Epoch 189/300\n",
      "306/306 [==============================] - 175s 571ms/step - loss: 1.5382 - yolo_loss_layer_1_loss: 0.4217 - yolo_loss_layer_2_loss: 0.0349 - yolo_loss_layer_3_loss: 1.2907e-04 - val_loss: 3.5453 - val_yolo_loss_layer_1_loss: 2.4321 - val_yolo_loss_layer_2_loss: 0.0341 - val_yolo_loss_layer_3_loss: 1.3338e-04\n",
      "Epoch 190/300\n",
      "306/306 [==============================] - 179s 585ms/step - loss: 1.5194 - yolo_loss_layer_1_loss: 0.4051 - yolo_loss_layer_2_loss: 0.0375 - yolo_loss_layer_3_loss: 1.3570e-04 - val_loss: 3.4121 - val_yolo_loss_layer_1_loss: 2.3014 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 1.1768e-04\n",
      "Epoch 191/300\n",
      "306/306 [==============================] - 158s 515ms/step - loss: 1.5323 - yolo_loss_layer_1_loss: 0.4199 - yolo_loss_layer_2_loss: 0.0404 - yolo_loss_layer_3_loss: 1.2288e-04 - val_loss: 3.3704 - val_yolo_loss_layer_1_loss: 2.2655 - val_yolo_loss_layer_2_loss: 0.0355 - val_yolo_loss_layer_3_loss: 1.1247e-04\n",
      "Epoch 192/300\n",
      "306/306 [==============================] - 174s 568ms/step - loss: 1.5203 - yolo_loss_layer_1_loss: 0.4189 - yolo_loss_layer_2_loss: 0.0345 - yolo_loss_layer_3_loss: 1.2230e-04 - val_loss: 3.5557 - val_yolo_loss_layer_1_loss: 2.4563 - val_yolo_loss_layer_2_loss: 0.0347 - val_yolo_loss_layer_3_loss: 1.3791e-04\n",
      "Epoch 193/300\n",
      "306/306 [==============================] - 169s 551ms/step - loss: 1.5136 - yolo_loss_layer_1_loss: 0.4132 - yolo_loss_layer_2_loss: 0.0380 - yolo_loss_layer_3_loss: 1.2584e-04 - val_loss: 3.5170 - val_yolo_loss_layer_1_loss: 2.4236 - val_yolo_loss_layer_2_loss: 0.0335 - val_yolo_loss_layer_3_loss: 1.2886e-04\n",
      "Epoch 194/300\n",
      "306/306 [==============================] - 168s 549ms/step - loss: 1.5361 - yolo_loss_layer_1_loss: 0.4384 - yolo_loss_layer_2_loss: 0.0400 - yolo_loss_layer_3_loss: 1.2446e-04 - val_loss: 3.5044 - val_yolo_loss_layer_1_loss: 2.4140 - val_yolo_loss_layer_2_loss: 0.0350 - val_yolo_loss_layer_3_loss: 1.2963e-04\n",
      "Epoch 195/300\n",
      "306/306 [==============================] - 182s 596ms/step - loss: 1.4692 - yolo_loss_layer_1_loss: 0.3805 - yolo_loss_layer_2_loss: 0.0355 - yolo_loss_layer_3_loss: 1.3559e-04 - val_loss: 3.5437 - val_yolo_loss_layer_1_loss: 2.4595 - val_yolo_loss_layer_2_loss: 0.0334 - val_yolo_loss_layer_3_loss: 1.2683e-04\n",
      "Epoch 196/300\n",
      "306/306 [==============================] - 170s 557ms/step - loss: 1.4961 - yolo_loss_layer_1_loss: 0.4092 - yolo_loss_layer_2_loss: 0.0384 - yolo_loss_layer_3_loss: 1.2785e-04 - val_loss: 3.3609 - val_yolo_loss_layer_1_loss: 2.2811 - val_yolo_loss_layer_2_loss: 0.0335 - val_yolo_loss_layer_3_loss: 1.2239e-04\n",
      "Epoch 197/300\n",
      "306/306 [==============================] - 160s 522ms/step - loss: 1.5019 - yolo_loss_layer_1_loss: 0.4165 - yolo_loss_layer_2_loss: 0.0413 - yolo_loss_layer_3_loss: 1.2328e-04 - val_loss: 3.5556 - val_yolo_loss_layer_1_loss: 2.4776 - val_yolo_loss_layer_2_loss: 0.0362 - val_yolo_loss_layer_3_loss: 1.1118e-04\n",
      "Epoch 198/300\n",
      "306/306 [==============================] - 165s 540ms/step - loss: 1.4879 - yolo_loss_layer_1_loss: 0.4099 - yolo_loss_layer_2_loss: 0.0384 - yolo_loss_layer_3_loss: 1.2256e-04 - val_loss: 3.4120 - val_yolo_loss_layer_1_loss: 2.3400 - val_yolo_loss_layer_2_loss: 0.0347 - val_yolo_loss_layer_3_loss: 1.2086e-04\n",
      "Epoch 199/300\n",
      "306/306 [==============================] - 173s 564ms/step - loss: 1.4447 - yolo_loss_layer_1_loss: 0.3752 - yolo_loss_layer_2_loss: 0.0344 - yolo_loss_layer_3_loss: 1.3087e-04 - val_loss: 3.3163 - val_yolo_loss_layer_1_loss: 2.2494 - val_yolo_loss_layer_2_loss: 0.0342 - val_yolo_loss_layer_3_loss: 1.2382e-04\n",
      "Epoch 200/300\n",
      "306/306 [==============================] - 179s 585ms/step - loss: 1.4592 - yolo_loss_layer_1_loss: 0.3898 - yolo_loss_layer_2_loss: 0.0393 - yolo_loss_layer_3_loss: 1.3206e-04 - val_loss: 3.3231 - val_yolo_loss_layer_1_loss: 2.2588 - val_yolo_loss_layer_2_loss: 0.0365 - val_yolo_loss_layer_3_loss: 1.2856e-04\n",
      "Epoch 201/300\n",
      "306/306 [==============================] - 163s 533ms/step - loss: 1.4667 - yolo_loss_layer_1_loss: 0.4024 - yolo_loss_layer_2_loss: 0.0391 - yolo_loss_layer_3_loss: 1.2059e-04 - val_loss: 3.4745 - val_yolo_loss_layer_1_loss: 2.4170 - val_yolo_loss_layer_2_loss: 0.0345 - val_yolo_loss_layer_3_loss: 1.2674e-04\n",
      "Epoch 202/300\n",
      "306/306 [==============================] - 182s 595ms/step - loss: 1.4567 - yolo_loss_layer_1_loss: 0.3983 - yolo_loss_layer_2_loss: 0.0377 - yolo_loss_layer_3_loss: 1.3586e-04 - val_loss: 3.5028 - val_yolo_loss_layer_1_loss: 2.4455 - val_yolo_loss_layer_2_loss: 0.0389 - val_yolo_loss_layer_3_loss: 1.2814e-04\n",
      "Epoch 203/300\n",
      "306/306 [==============================] - 181s 593ms/step - loss: 1.4315 - yolo_loss_layer_1_loss: 0.3789 - yolo_loss_layer_2_loss: 0.0363 - yolo_loss_layer_3_loss: 1.3428e-04 - val_loss: 3.6336 - val_yolo_loss_layer_1_loss: 2.5825 - val_yolo_loss_layer_2_loss: 0.0371 - val_yolo_loss_layer_3_loss: 1.2414e-04\n",
      "Epoch 204/300\n",
      "306/306 [==============================] - 175s 570ms/step - loss: 1.4516 - yolo_loss_layer_1_loss: 0.4046 - yolo_loss_layer_2_loss: 0.0352 - yolo_loss_layer_3_loss: 1.2953e-04 - val_loss: 3.4098 - val_yolo_loss_layer_1_loss: 2.3651 - val_yolo_loss_layer_2_loss: 0.0352 - val_yolo_loss_layer_3_loss: 1.2257e-04\n",
      "Epoch 205/300\n",
      "306/306 [==============================] - 178s 582ms/step - loss: 1.4362 - yolo_loss_layer_1_loss: 0.3906 - yolo_loss_layer_2_loss: 0.0384 - yolo_loss_layer_3_loss: 1.3251e-04 - val_loss: 3.4147 - val_yolo_loss_layer_1_loss: 2.3727 - val_yolo_loss_layer_2_loss: 0.0371 - val_yolo_loss_layer_3_loss: 1.2093e-04\n",
      "Epoch 206/300\n",
      "306/306 [==============================] - 156s 511ms/step - loss: 1.4794 - yolo_loss_layer_1_loss: 0.4343 - yolo_loss_layer_2_loss: 0.0422 - yolo_loss_layer_3_loss: 1.2133e-04 - val_loss: 3.3899 - val_yolo_loss_layer_1_loss: 2.3551 - val_yolo_loss_layer_2_loss: 0.0341 - val_yolo_loss_layer_3_loss: 1.0992e-04\n",
      "Epoch 207/300\n",
      "306/306 [==============================] - 182s 595ms/step - loss: 1.4102 - yolo_loss_layer_1_loss: 0.3719 - yolo_loss_layer_2_loss: 0.0398 - yolo_loss_layer_3_loss: 1.3022e-04 - val_loss: 3.3849 - val_yolo_loss_layer_1_loss: 2.3462 - val_yolo_loss_layer_2_loss: 0.0424 - val_yolo_loss_layer_3_loss: 1.1950e-04\n",
      "Epoch 208/300\n",
      "306/306 [==============================] - 164s 537ms/step - loss: 1.4357 - yolo_loss_layer_1_loss: 0.4068 - yolo_loss_layer_2_loss: 0.0347 - yolo_loss_layer_3_loss: 1.2313e-04 - val_loss: 3.3420 - val_yolo_loss_layer_1_loss: 2.3160 - val_yolo_loss_layer_2_loss: 0.0341 - val_yolo_loss_layer_3_loss: 1.3011e-04\n",
      "Epoch 209/300\n",
      "306/306 [==============================] - 188s 613ms/step - loss: 1.4299 - yolo_loss_layer_1_loss: 0.4021 - yolo_loss_layer_2_loss: 0.0381 - yolo_loss_layer_3_loss: 1.3771e-04 - val_loss: 3.4000 - val_yolo_loss_layer_1_loss: 2.3791 - val_yolo_loss_layer_2_loss: 0.0332 - val_yolo_loss_layer_3_loss: 1.2542e-04\n",
      "Epoch 210/300\n",
      "306/306 [==============================] - 170s 555ms/step - loss: 1.3769 - yolo_loss_layer_1_loss: 0.3567 - yolo_loss_layer_2_loss: 0.0348 - yolo_loss_layer_3_loss: 1.2271e-04 - val_loss: 3.2998 - val_yolo_loss_layer_1_loss: 2.2833 - val_yolo_loss_layer_2_loss: 0.0335 - val_yolo_loss_layer_3_loss: 1.3383e-04\n",
      "Epoch 211/300\n",
      "306/306 [==============================] - 180s 587ms/step - loss: 1.4081 - yolo_loss_layer_1_loss: 0.3932 - yolo_loss_layer_2_loss: 0.0339 - yolo_loss_layer_3_loss: 1.3619e-04 - val_loss: 3.3443 - val_yolo_loss_layer_1_loss: 2.3321 - val_yolo_loss_layer_2_loss: 0.0334 - val_yolo_loss_layer_3_loss: 1.0938e-04\n",
      "Epoch 212/300\n",
      "306/306 [==============================] - 162s 530ms/step - loss: 1.3996 - yolo_loss_layer_1_loss: 0.3823 - yolo_loss_layer_2_loss: 0.0406 - yolo_loss_layer_3_loss: 1.2058e-04 - val_loss: 3.5141 - val_yolo_loss_layer_1_loss: 2.5048 - val_yolo_loss_layer_2_loss: 0.0349 - val_yolo_loss_layer_3_loss: 1.1910e-04\n",
      "Epoch 213/300\n",
      "306/306 [==============================] - 175s 572ms/step - loss: 1.4024 - yolo_loss_layer_1_loss: 0.3935 - yolo_loss_layer_2_loss: 0.0367 - yolo_loss_layer_3_loss: 1.2797e-04 - val_loss: 3.2743 - val_yolo_loss_layer_1_loss: 2.2698 - val_yolo_loss_layer_2_loss: 0.0342 - val_yolo_loss_layer_3_loss: 1.2883e-04\n",
      "Epoch 214/300\n",
      "306/306 [==============================] - 157s 514ms/step - loss: 1.3864 - yolo_loss_layer_1_loss: 0.3793 - yolo_loss_layer_2_loss: 0.0389 - yolo_loss_layer_3_loss: 1.1893e-04 - val_loss: 3.4172 - val_yolo_loss_layer_1_loss: 2.4147 - val_yolo_loss_layer_2_loss: 0.0364 - val_yolo_loss_layer_3_loss: 1.1438e-04\n",
      "Epoch 215/300\n",
      "306/306 [==============================] - 168s 550ms/step - loss: 1.3858 - yolo_loss_layer_1_loss: 0.3832 - yolo_loss_layer_2_loss: 0.0387 - yolo_loss_layer_3_loss: 1.2722e-04 - val_loss: 3.3531 - val_yolo_loss_layer_1_loss: 2.3525 - val_yolo_loss_layer_2_loss: 0.0388 - val_yolo_loss_layer_3_loss: 1.1159e-04\n",
      "Epoch 216/300\n",
      "306/306 [==============================] - 171s 560ms/step - loss: 1.3749 - yolo_loss_layer_1_loss: 0.3739 - yolo_loss_layer_2_loss: 0.0414 - yolo_loss_layer_3_loss: 1.2489e-04 - val_loss: 3.4814 - val_yolo_loss_layer_1_loss: 2.4887 - val_yolo_loss_layer_2_loss: 0.0355 - val_yolo_loss_layer_3_loss: 1.2854e-04\n",
      "Epoch 217/300\n",
      "306/306 [==============================] - 174s 568ms/step - loss: 1.3965 - yolo_loss_layer_1_loss: 0.3951 - yolo_loss_layer_2_loss: 0.0462 - yolo_loss_layer_3_loss: 1.2857e-04 - val_loss: 3.3999 - val_yolo_loss_layer_1_loss: 2.4062 - val_yolo_loss_layer_2_loss: 0.0405 - val_yolo_loss_layer_3_loss: 1.2210e-04\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 00217: early stopping\n",
      "Wall time: 10h 24min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=300,\n",
    "    callbacks=callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_string = train_model.to_json()\n",
    "with open('yolo.json', 'w') as json_file:\n",
    "    json_file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.save_weights('yolo_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.save('yolo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_mode.load_weights('yolo_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'conv2d_59/BiasAdd:0' shape=(?, ?, ?, 21) dtype=float32>, <tf.Tensor 'conv2d_67/BiasAdd:0' shape=(?, ?, ?, 21) dtype=float32>, <tf.Tensor 'conv2d_75/BiasAdd:0' shape=(?, ?, ?, 21) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(infer_mode.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yolo_test.chkp'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(sess.graph_def, '', 'yolo_test.pb', as_text=False)\n",
    "tf.train.write_graph(sess.graph_def, '', 'yolo_graph.pbtxt')\n",
    "tf.train.Saver().save(sess, 'yolo_test.chkp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from yolo_test.chkp\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 363 variables.\n",
      "INFO:tensorflow:Converted 363 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "output_node_name = 'conv2d_59/BiasAdd,conv2d_67/BiasAdd,conv2d_75/BiasAdd'\n",
    "fg = freeze_graph.freeze_graph('yolo_graph.pbtxt',\n",
    "                         None, False,\n",
    "                         'yolo_test.chkp',\n",
    "                         output_node_name,\n",
    "                         'save/restore_all',\n",
    "                         'save/Const:0',\n",
    "                         'yolo_test.pb',\n",
    "                         True, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.tools import optimize_for_inference_lib\n",
    "# graph_def = tf.GraphDef()\n",
    "# with tf.gfile.Open('yolo_test.pb', \"rb\") as f:\n",
    "#     graph_def.ParseFromString(f.read())\n",
    "\n",
    "# output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "#     graph_def, ['input_1'], [output_node_name], tf.float32.as_datatype_enum)\n",
    "\n",
    "# with tf.gfile.GFile('yolo_test.pb', \"wb\") as f:\n",
    "#     f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "# # Strip Const nodes.\n",
    "# for i in reversed(range(len(graph_def.node))):\n",
    "#     if graph_def.node[i].op == 'Const':\n",
    "#         del graph_def.node[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.train.write_graph(graph_def, '', 'yolo_test.pbtxt', as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\dnn\\src\\tensorflow\\tf_graph_simplifier.cpp:890: error: (-2:Unspecified error) Tensor's data type is not supported in function 'cv::dnn::dnn4_v20190621::getTensorContent'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b42bb441fd24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNetFromTensorflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolo_test.pb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\dnn\\src\\tensorflow\\tf_graph_simplifier.cpp:890: error: (-2:Unspecified error) Tensor's data type is not supported in function 'cv::dnn::dnn4_v20190621::getTensorContent'\n"
     ]
    }
   ],
   "source": [
    "net = cv2.dnn.readNetFromTensorflow('yolo_test.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-b5a7226b339b>:31: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\rtav\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 650 variables.\n",
      "INFO:tensorflow:Converted 650 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in infer_mode.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yolo_test1.pb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(frozen_graph, '', 'yolo_test1.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.dnn_registerLayer('YoloLossLayer', YoloLossLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn.readNetFromTensorflow('yolo_test1.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.tools.graph_transforms import TransformGraph\n",
    "# from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "# graph = 'yolo_test2.pb'\n",
    "# with tf.gfile.FastGFile(graph,'rb') as f:\n",
    "#     graph_def = tf.GraphDef()\n",
    "#     graph_def.ParseFromString(f.read())\n",
    "#     tf.summary.FileWriter('logs', graph_def)\n",
    "\n",
    "#     inp_node = 'input_1'\n",
    "#     out_node = ['conv2d_59/BiasAdd','conv2d_67/BiasAdd','conv2d_75/BiasAdd']\n",
    "#     graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def, [inp_node], [out_node], tf.float32.as_datatype_enum)\n",
    "#     graph_def = TransformGraph(graph_def, [inp_node], [out_node], [\"sort_by_execution_order\"])\n",
    " \n",
    "#     with tf.gfile.FastGFile('frozen_inference_graph_opt.pb', 'wb') as f:\n",
    "#         f.write(graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
